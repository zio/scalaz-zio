"use strict";(self.webpackChunkzio_site=self.webpackChunkzio_site||[]).push([[68248],{28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>r});var o=t(96540);const a={},i=o.createContext(a);function s(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),o.createElement(i.Provider,{value:n},e.children)}},98235:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>o,toc:()=>m});const o=JSON.parse('{"id":"zio-kafka/preventing-duplicates","title":"Preventing duplicates","description":"In zio-kafka processing of records runs asynchronously with partition management. This brings substantial performance","source":"@site/docs/zio-kafka/preventing-duplicates.md","sourceDirName":"zio-kafka","slug":"/zio-kafka/preventing-duplicates","permalink":"/zio-kafka/preventing-duplicates","draft":false,"unlisted":false,"editUrl":"https://github.com/zio/zio/edit/series/2.x/docs/zio-kafka/preventing-duplicates.md","tags":[],"version":"current","frontMatter":{"id":"preventing-duplicates","title":"Preventing duplicates"},"sidebar":"ecosystem-sidebar","previous":{"title":"Tuning the consumer","permalink":"/zio-kafka/consumer-tuning"},"next":{"title":"Sharing a Consumer between multiple streams","permalink":"/zio-kafka/sharing-consumer"}}');var a=t(74848),i=t(28453);const s={id:"preventing-duplicates",title:"Preventing duplicates"},r=void 0,c={},m=[{value:"Commit to an external system",id:"commit-to-an-external-system",level:3},{value:"Commit with a transactional producer",id:"commit-with-a-transactional-producer",level:3},{value:"More information",id:"more-information",level:2}];function l(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",p:"p",pre:"pre",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(n.p,{children:["In zio-kafka processing of records runs asynchronously with partition management. This brings substantial performance\nadvantages but causes some records to be consumed and processed ",(0,a.jsx)(n.em,{children:"twice"})," when a rebalance occurs. To prevent this,\nsince version 2.7.1 zio-kafka supports a new mode in which we prevent duplicates due to rebalances. You can enable it\nas follows:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-scala",children:'import zio.*\nimport zio.kafka.consumer.ConsumerSettings\n\nval consumerSettings: ConsumerSettings =\n  ConsumerSettings(List("localhost:9092"))\n    .withGroupId("group")\n    .withRebalanceSafeCommits(true)       // enable rebalance-safe-commits mode\n    .withMaxRebalanceDuration(30.seconds) // defaults to 3 minutes\n'})}),"\n",(0,a.jsx)(n.p,{children:"With rebalance-safe-commits mode enabled, rebalances are held up for up to max-rebalance-duration to wait for pending\ncommits to be completed. Once pending commits are completed, it is safe for another consumer in the group to take over\na partition."}),"\n",(0,a.jsx)(n.p,{children:"For this to work correctly, your program must process a chunk of records within max-rebalance-duration. The clock\nstarts the moment the chunk is pushed into the stream and ends when the commits for these records complete."}),"\n",(0,a.jsxs)(n.p,{children:["In addition, your program must commit the offsets of consumed records. The most straightforward way is to commit to the\nKafka brokers. This is done by calling ",(0,a.jsx)(n.code,{children:".commit"})," on the offset of consumed records (see the consumer documentation).\nHowever, there are more options: external commits and transactional producing."]}),"\n",(0,a.jsx)(n.h3,{id:"commit-to-an-external-system",children:"Commit to an external system"}),"\n",(0,a.jsxs)(n.p,{children:["When you commit to an external system (e.g. by writing to a relational database) the zio-kafka consumer needs to know\nabout those commits before it can work in rebalance-safe-commits mode. Inform zio-kafka about external commits by\ninvoking method ",(0,a.jsx)(n.code,{children:"Consumer.registerExternalCommits(offsetBatch: OffsetBatch)"})," (available since zio-kafka 2.10.0)."]}),"\n",(0,a.jsx)(n.p,{children:"Here is what this could look like:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-scala",children:'import zio.kafka.consumer._\n\nconsumer.plainStream(Subscription.topics("topic2000"), Serde.string, Serde.string)\n  .mapZIO { record =>\n    database.store(record.offset) *> // <-- the external commit\n      consumer.registerExternalCommits(OffsetBatch(record.offset))\n  }\n  .runDrain\n'})}),"\n",(0,a.jsx)(n.h3,{id:"commit-with-a-transactional-producer",children:"Commit with a transactional producer"}),"\n",(0,a.jsxs)(n.p,{children:["Although transactional producing is possible with zio-kafka, it is not easy and the code is very messy (see\n",(0,a.jsx)(n.code,{children:"ConsumerSpec"})," for an example). Transactional producing can not be used in combination with rebalance-safe-commits mode."]}),"\n",(0,a.jsx)(n.p,{children:"Zio-kafka v3.0.0 will make transactional producing much easier."}),"\n",(0,a.jsx)(n.h2,{id:"more-information",children:"More information"}),"\n",(0,a.jsxs)(n.p,{children:["There is more information in the scaladocs of ",(0,a.jsx)(n.code,{children:"ConsumerSettings"})," and the description of\n",(0,a.jsx)(n.a,{href:"https://github.com/zio/zio-kafka/pull/1098",children:"pull request #1098"})," that introduced this feature.\nYou can also watch the presentation\n",(0,a.jsx)(n.a,{href:"https://www.youtube.com/watch?v=MJoRwEyyVxM",children:"Making ZIO-Kafka Safer And Faster"}),". The relevant part starts at 10:24."]})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(l,{...e})}):l(e)}}}]);