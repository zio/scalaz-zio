"use strict";(self.webpackChunkzio_site=self.webpackChunkzio_site||[]).push([[51207],{28453:(e,n,a)=>{a.d(n,{R:()=>t,x:()=>o});var s=a(96540);const i={},r=s.createContext(i);function t(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),s.createElement(r.Provider,{value:n},e.children)}},74222:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"zio-kafka/serialization-and-deserialization","title":"Serialization and Deserialization","description":"Zio-kafka deserializes incoming data, and deserializes outgoing data (both keys and values) from byte arrays to any","source":"@site/docs/zio-kafka/serialization-and-deserialization.md","sourceDirName":"zio-kafka","slug":"/zio-kafka/serialization-and-deserialization","permalink":"/zio-kafka/serialization-and-deserialization","draft":false,"unlisted":false,"editUrl":"https://github.com/zio/zio/edit/series/2.x/docs/zio-kafka/serialization-and-deserialization.md","tags":[],"version":"current","frontMatter":{"id":"serialization-and-deserialization","title":"Serialization and Deserialization"},"sidebar":"ecosystem-sidebar","previous":{"title":"Sharing a Consumer between multiple streams","permalink":"/zio-kafka/sharing-consumer"},"next":{"title":"Writing Tests with the `zio-kafka-testkit` library","permalink":"/zio-kafka/writing-tests"}}');var i=a(74848),r=a(28453);const t={id:"serialization-and-deserialization",title:"Serialization and Deserialization"},o=void 0,d={},c=[{value:"Handling failures in a serde",id:"handling-failures-in-a-serde",level:2},{value:"Custom Data Type Serdes",id:"custom-data-type-serdes",level:2},{value:"Custom serdes that wraps invalid data",id:"custom-serdes-that-wraps-invalid-data",level:2},{value:"Deserialization in the consumer stream",id:"deserialization-in-the-consumer-stream",level:2},{value:"A warning about <code>mapZIO</code>",id:"a-warning-about-mapzio",level:2},{value:"Use <code>chunksWith</code>",id:"use-chunkswith",level:3},{value:"Expose chunking structure with <code>chunks</code>",id:"expose-chunking-structure-with-chunks",level:3}];function l(e){const n={code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["Zio-kafka deserializes incoming data, and deserializes outgoing data (both keys and values) from byte arrays to any\nother type and back. This works by providing a key and value ",(0,i.jsx)(n.code,{children:"Deserializer"})," while constructing a ",(0,i.jsx)(n.code,{children:"Consumer"}),",\nand a key and value ",(0,i.jsx)(n.code,{children:"Serializer"})," while constructing the ",(0,i.jsx)(n.code,{children:"Producer"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["A ",(0,i.jsx)(n.code,{children:"Serde"})," combines a ",(0,i.jsx)(n.code,{children:"Deserializer"})," and a ",(0,i.jsx)(n.code,{children:"Serializer"}),". Common serdes are provided in the ",(0,i.jsx)(n.code,{children:"Serdes"})," object, e.g.\n",(0,i.jsx)(n.code,{children:"Serdes.byteArray"}),", ",(0,i.jsx)(n.code,{children:"Serdes.string"})," and ",(0,i.jsx)(n.code,{children:"Serdes.long"}),". A serde can be converted to other serdes, or you can create a\ncustom serde by implementing the ",(0,i.jsx)(n.code,{children:"Serde"})," trait directly."]}),"\n",(0,i.jsx)(n.p,{children:"This document contains:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Handling failures in a serde"}),"\n",(0,i.jsx)(n.li,{children:"How to create a custom serde"}),"\n",(0,i.jsx)(n.li,{children:"How to create and use a custom serde that wraps invalid data"}),"\n",(0,i.jsx)(n.li,{children:"How to do deserialization in the consumer stream"}),"\n",(0,i.jsxs)(n.li,{children:["A warning about using ",(0,i.jsx)(n.code,{children:"mapZIO"})]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"handling-failures-in-a-serde",children:"Handling failures in a serde"}),"\n",(0,i.jsxs)(n.p,{children:["Ideally, a serde can not fail serializing and deserializing. This is for example the case with the provided\n",(0,i.jsx)(n.code,{children:"Serdes.byteArray"})," and ",(0,i.jsx)(n.code,{children:"Serdes.string"}),". This is not the case for any serde that needs to handle invalid input,\n(for example ",(0,i.jsx)(n.code,{children:"Serdes.long"}),"), or a serde that needs to do a remote lookup."]}),"\n",(0,i.jsx)(n.p,{children:"By default, a consumer stream will fail if it encounters a deserialization error in the serde. Unfortunately, the\nresulting failure might not clearly indicate that the cause is in the serde."}),"\n",(0,i.jsx)(n.p,{children:"There are 2 solutions for improving this:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Wrap the result of the serde in a ",(0,i.jsx)(n.code,{children:"Try"})," with the ",(0,i.jsx)(n.code,{children:"Serde.asTry"})," method."]}),"\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.code,{children:"Serdes.byteArray"}),", put the deserialization code in the consumer stream, or do serialization before handing the\ndata to zio-kafka. This way you can handle failures any way you want."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Both approaches are discussed further below."}),"\n",(0,i.jsx)(n.h2,{id:"custom-data-type-serdes",children:"Custom Data Type Serdes"}),"\n",(0,i.jsxs)(n.p,{children:["Serializers and deserializers for custom data types can be created from scratch, or by converting existing\nserdes. For example, to create a serde for an ",(0,i.jsx)(n.code,{children:"Instant"})," from a serde for a ",(0,i.jsx)(n.code,{children:"Long"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-scala",children:"import java.time.Instant\nimport zio.kafka.serde._\n\nval instantSerde: Serde[Any, Instant] =\n  Serdes.long.inmap(java.time.Instant.ofEpochMilli)(_.toEpochMilli)\n"})}),"\n",(0,i.jsxs)(n.p,{children:["To handle missing data (an empty key or value), you can use the ",(0,i.jsx)(n.code,{children:"Serde.asOption"})," transformer. For example:\n",(0,i.jsx)(n.code,{children:"Serdes.string.asOption"}),". This results in a ",(0,i.jsx)(n.code,{children:"None"})," if the key or value is empty, and in a ",(0,i.jsx)(n.code,{children:"Some(string)"})," otherwise."]}),"\n",(0,i.jsx)(n.h2,{id:"custom-serdes-that-wraps-invalid-data",children:"Custom serdes that wraps invalid data"}),"\n",(0,i.jsxs)(n.p,{children:["Any ",(0,i.jsx)(n.code,{children:"Deserializer[A]"})," for a given type ",(0,i.jsx)(n.code,{children:"A"})," can be converted into  a ",(0,i.jsx)(n.code,{children:"Deserializer[Try[A]]"})," where deserialization\nfailures are converted to a ",(0,i.jsx)(n.code,{children:"Failure"})," using the ",(0,i.jsx)(n.code,{children:"asTry"})," method. (Method ",(0,i.jsx)(n.code,{children:"asTry"})," is also available on ",(0,i.jsx)(n.code,{children:"Serde"}),".)"]}),"\n",(0,i.jsx)(n.p,{children:"Below is an example of skipping records that fail to deserialize. The offset is passed downstream to be committed."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-scala",children:'import zio._, stream._\nimport zio.kafka.consumer._\nimport zio.kafka.serde._\nimport scala.util.{Try, Success, Failure}\n\nval keySerde = Serdes.string\nval valueSerde = Serdes.string.asTry   // <-- using `.asTry`\n\nConsumer.make(consumerSettings).flatMap { consumer =>\n  consumer\n    .plainStream(Subscription.topics("topic150"), keySerde, valueSerde)\n    .mapZIO { record => // \u26a0\ufe0f see section about `mapZIO` below!\n      val tryValue: Try[String] = record.record.value()\n      val offset: Offset = record.offset\n\n      tryValue match {\n        case Success(value) =>\n          // Action for successful deserialization\n          someEffect(value).as(offset)\n        case Failure(exception) =>\n          // Possibly log the exception or take alternative action\n          ZIO.succeed(offset)\n      }\n    }\n    .aggregateAsync(Consumer.offsetBatches)\n    .mapZIO(_.commit)\n    .runDrain\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"deserialization-in-the-consumer-stream",children:"Deserialization in the consumer stream"}),"\n",(0,i.jsxs)(n.p,{children:["In this approach we provide zio-kafka with the ",(0,i.jsx)(n.code,{children:"Serdes.byteArray"})," serde (which is a pass-through serde) and do the\ndeserialization in the consumer stream. The deserialization can be done with regular ZIO operators."]}),"\n",(0,i.jsx)(n.p,{children:"This approach provides more freedom at the cost of having to write more code. It also allows for optimizations such as\noperating on chunks of records (see next section), and more contextual failure handling."}),"\n",(0,i.jsx)(n.p,{children:"Here is an example:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-scala",children:'import zio._, stream._\nimport zio.kafka.consumer._\n\ndef deserialize(value: Array[Byte]): ZIO[Any, Throwable, Message] = ???\n\nConsumer.make(consumerSettings).flatMap { consumer =>\n  consumer\n    .plainStream(Subscription.topics("topic150"), Serde.byteArray, Serde.byteArray)\n    .mapZIO { record => // \u26a0\ufe0f see section about `mapZIO` below!\n      val value: Array[Byte] = record.record.value()\n      val offset: Offset = record.offset\n\n      deserialize(value)\n        // possible action to take if deserialization fails:\n        .recoverWith(_ => someEffect(value))\n        .flatMap(processMessage)\n        .as(offset)\n    }\n    .aggregateAsync(Consumer.offsetBatches)\n    .mapZIO(_.commit)\n    .runDrain\n}\n'})}),"\n",(0,i.jsxs)(n.h2,{id:"a-warning-about-mapzio",children:["A warning about ",(0,i.jsx)(n.code,{children:"mapZIO"})]}),"\n",(0,i.jsxs)(n.p,{children:["Be careful with using ",(0,i.jsx)(n.code,{children:"mapZIO"})," as it breaks the chunking structure of the stream (or more precisely, the resulting\nstream has chunks with a single element). Throughput can be considerably lower than with the chunking structure intact."]}),"\n",(0,i.jsx)(n.p,{children:"If your application requirements allow all elements of a chunk to be processed in one go, then you can use one of these\ntechniques to preserve the chunking structure:"}),"\n",(0,i.jsxs)(n.h3,{id:"use-chunkswith",children:["Use ",(0,i.jsx)(n.code,{children:"chunksWith"})]}),"\n",(0,i.jsxs)(n.p,{children:["Use ",(0,i.jsx)(n.code,{children:"chunksWith"})," when you have a single processing step that needs to work on a chunk."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-scala",children:"def f(a: A): ZIO[R, E, B]\n\nstream                                        // ZStream[R, E, A]\n  .chunksWith { stream => stream.mapZIO(f) }  // ZStream[R, E, B]\n"})}),"\n",(0,i.jsxs)(n.h3,{id:"expose-chunking-structure-with-chunks",children:["Expose chunking structure with ",(0,i.jsx)(n.code,{children:"chunks"})]}),"\n",(0,i.jsxs)(n.p,{children:["Use ",(0,i.jsx)(n.code,{children:"chunks"})," when you have multiple processing steps that can all work on a chunk at a time. Since ",(0,i.jsx)(n.code,{children:"chunks"})," exposes the\nchunking structure explicitly, the program can no longer accidentally break the chunking structure (unless\n",(0,i.jsx)(n.code,{children:"flattenChunks"})," is also used)."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-scala",children:"def f(a: A): ZIO[R, E, B]\ndef g(b: B): ZIO[R, E, C]\n\nstream                                         // ZStream[R, E, A]\n  .chunks                                      // ZStream[R, E, Chunk[A]]\n  .mapZIO { chunk => ZIO.foreach(chunk)(f) }   // ZStream[R, E, Chunk[B]]\n  .mapZIO { chunk => ZIO.foreach(chunk)(g) }   // ZStream[R, E, Chunk[C]]\n  .flattenChunks                               // ZStream[R, E, C]\n"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}}}]);