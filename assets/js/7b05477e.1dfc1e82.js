"use strict";(self.webpackChunkzio_site=self.webpackChunkzio_site||[]).push([[75878],{28453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>s});var i=n(96540);const a={},o=i.createContext(a);function r(e){const t=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(o.Provider,{value:t},e.children)}},77784:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"zio-dynamodb/reference/auto-batching-and-parallelisation","title":"Auto batching and parallelisation","description":"When DynamoDBQuery\'s are composed either manually via the zip combinator or automatically using the DynamoDBQuery.forEach function they become eligible for auto-batching and parallelisation in the execute method.","source":"@site/docs/zio-dynamodb/reference/auto-batching-and-parallelisation.md","sourceDirName":"zio-dynamodb/reference","slug":"/zio-dynamodb/reference/auto-batching-and-parallelisation","permalink":"/zio-dynamodb/reference/auto-batching-and-parallelisation","draft":false,"unlisted":false,"editUrl":"https://github.com/zio/zio/edit/series/2.x/docs/zio-dynamodb/reference/auto-batching-and-parallelisation.md","tags":[],"version":"current","frontMatter":{"id":"auto-batching-and-parallelisation","title":"Auto batching and parallelisation"},"sidebar":"ecosystem-sidebar","previous":{"title":"Error Handling","permalink":"/zio-dynamodb/reference/error-handling"},"next":{"title":"ZIO DynamoDB JSON Module","permalink":"/zio-dynamodb/reference/zio-dynamodb-json"}}');var a=n(74848),o=n(28453);const r={id:"auto-batching-and-parallelisation",title:"Auto batching and parallelisation"},s=void 0,c={},l=[{value:"Rules for determining auto-batching vs parallelisation behaviour",id:"rules-for-determining-auto-batching-vs-parallelisation-behaviour",level:2},{value:"Maximum batch sizes for <code>BatchWriteItem</code> and <code>BatchGetItem</code>",id:"maximum-batch-sizes-for-batchwriteitem-and-batchgetitem",level:2},{value:"Automatic retry of unprocessed batch items/keys",id:"automatic-retry-of-unprocessed-batch-itemskeys",level:2},{value:"Integration Batching with ZIO Streams",id:"integration-batching-with-zio-streams",level:2}];function d(e){const t={a:"a",code:"code",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(t.p,{children:["When ",(0,a.jsx)(t.code,{children:"DynamoDBQuery"}),"'s are composed either manually via the ",(0,a.jsx)(t.code,{children:"zip"})," combinator or automatically using the ",(0,a.jsx)(t.code,{children:"DynamoDBQuery.forEach"})," function they become eligible for auto-batching and parallelisation in the ",(0,a.jsx)(t.code,{children:"execute"})," method."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-scala",children:'val batchedWrite1 = DynamoDBQuery.put("person", Person("1", "John", 21))\n        .zip(DynamoDBQuery.put("person", Person("2", "Jane", 22)))\n\nval batchedWrite2 = DynamoDBQuery.forEach(people)(person => put("person", person))\n\nfor {\n  _ <- batchedWrite1.execute // PutItem operations will be batched\n  _ <- batchedWrite2.execute // PutItem operations will be batched\n} yield ()\n'})}),"\n",(0,a.jsx)(t.h2,{id:"rules-for-determining-auto-batching-vs-parallelisation-behaviour",children:"Rules for determining auto-batching vs parallelisation behaviour"}),"\n",(0,a.jsxs)(t.p,{children:["The rules for determining whether a query is auto-batched are determined by what query types are eligible for batching in the AWS API. The AWS ",(0,a.jsx)(t.a,{href:"https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_BatchWriteItem.html",children:"BatchWriteItem"})," operation can only deal with ",(0,a.jsx)(t.code,{children:"PutItem"})," and ",(0,a.jsx)(t.code,{children:"DeleteItem"})," operations. Furthermore, for both of these operations - condition expressions are not allowed. The AWS ",(0,a.jsx)(t.a,{href:"https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_GetItem.html",children:"BatchGetItem"})," operation is used for batching ",(0,a.jsx)(t.code,{children:"GetItems"}),"'s ."]}),"\n",(0,a.jsx)(t.p,{children:"So the rules are as follows:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["A query only qualifies for auto-batching  if it passes the following criteria:","\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["The query is a ",(0,a.jsx)(t.code,{children:"PutItem"})," or ",(0,a.jsx)(t.code,{children:"DeleteItem"})," operation (",(0,a.jsx)(t.code,{children:"put"})," and ",(0,a.jsx)(t.code,{children:"deleteFrom"})," in the High Level API)","\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"The query does not have a condition expression"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["The query is a ",(0,a.jsx)(t.code,{children:"GetItem"})," operation (",(0,a.jsx)(t.code,{children:"get"})," in the High Level API)","\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:["The query's ",(0,a.jsx)(t.code,{children:"projections"})," list contains the primary key - this is required to match the response data to the request. Note all fields are included by default so this is only a concern if you explicitly specify the projection expression."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(t.li,{children:"If a query does not qualify for auto-batching it will be parallelised automatically"}),"\n"]}),"\n",(0,a.jsxs)(t.h2,{id:"maximum-batch-sizes-for-batchwriteitem-and-batchgetitem",children:["Maximum batch sizes for ",(0,a.jsx)(t.code,{children:"BatchWriteItem"})," and ",(0,a.jsx)(t.code,{children:"BatchGetItem"})]}),"\n",(0,a.jsxs)(t.p,{children:["When using the ",(0,a.jsx)(t.code,{children:"zip"})," or ",(0,a.jsx)(t.code,{children:"forEach"})," operations one thing to bear in mind is the maximum number of queries that the ",(0,a.jsx)(t.code,{children:"BatchWriteItem"})," and ",(0,a.jsx)(t.code,{children:"BatchGetItem"})," operations can handle:"]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"BatchWriteItem"})," can handle up to ",(0,a.jsx)(t.strong,{children:"25"})," ",(0,a.jsx)(t.code,{children:"PutItem"})," or ",(0,a.jsx)(t.code,{children:"DeleteItem"})," operations"]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"BatchGetItem"})," can handle up to ",(0,a.jsx)(t.strong,{children:"100"})," ",(0,a.jsx)(t.code,{children:"GetItem"})," operations"]}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"If these are exceeded then you will get a runtime AWS error. For further information please refer to the AWS documentation linked above."}),"\n",(0,a.jsx)(t.h2,{id:"automatic-retry-of-unprocessed-batch-itemskeys",children:"Automatic retry of unprocessed batch items/keys"}),"\n",(0,a.jsxs)(t.p,{children:["Note that both the AWS ",(0,a.jsx)(t.code,{children:"BatchWriteItem"})," and ",(0,a.jsx)(t.code,{children:"BatchGetItem"})," operations return a list of unprocessed items/keys. If this list is non-empty then the operation are retried automatically by the ZIO DynamoDB library."]}),"\n",(0,a.jsxs)(t.p,{children:["If retries do not succeed in eliminating the unprocessed items/keys then the whole batch is failed with a ",(0,a.jsx)(t.code,{children:"BatchError.WriteError"}),"/",(0,a.jsx)(t.code,{children:"BatchError.GetError"})," - both of which will contain a list of the unprocessed items/keys."]}),"\n",(0,a.jsx)(t.p,{children:"The default retry policy is:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-scala",children:"Schedule.recurs(3) && Schedule.exponential(50.milliseconds)\n"})}),"\n",(0,a.jsxs)(t.p,{children:["This can be overridden by using the ",(0,a.jsx)(t.code,{children:"withRetryPolicy"})," combinator:"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-scala",children:"batchedWrite2.withRetryPolicy(myCustomRetryPolicy).execute\n"})}),"\n",(0,a.jsx)(t.h2,{id:"integration-batching-with-zio-streams",children:"Integration Batching with ZIO Streams"}),"\n",(0,a.jsxs)(t.p,{children:["For examples of how to integrate batching with ZIO Stream please see the utility functions ",(0,a.jsx)(t.code,{children:"batchWriteFromStream"})," and ",(0,a.jsx)(t.code,{children:"batchGetFromStream"})," in the ",(0,a.jsx)(t.code,{children:"zio.dynamodb"})," package.\nThese functions take care of details mentioned above such as managing the maximum batch sizes and can also be used as examples for writing your own custom batched streaming operations."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-scalaa"})})]})}function h(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);