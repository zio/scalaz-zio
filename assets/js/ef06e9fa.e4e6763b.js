"use strict";(self.webpackChunkzio_site=self.webpackChunkzio_site||[]).push([[90405],{49762:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"zio-flow/internals","title":"Internals","description":"This page contains information about some implementation details of ZIO Flow which are not necessary to know about for","source":"@site/docs/zio-flow/internals.md","sourceDirName":"zio-flow","slug":"/zio-flow/internals","permalink":"/zio-flow/internals","draft":false,"unlisted":false,"editUrl":"https://github.com/zio/zio/edit/series/2.x/docs/zio-flow/internals.md","tags":[],"version":"current","frontMatter":{"id":"internals","title":"Internals"},"sidebar":"ecosystem-sidebar","previous":{"title":"Examples","permalink":"/zio-flow/examples"},"next":{"title":"ZIO HTTP","permalink":"/zio-http/"}}');var a=t(74848),s=t(28453);const r={id:"internals",title:"Internals"},o="Internals",l={},c=[{value:"The Remote type",id:"the-remote-type",level:2},{value:"Schemas and dynamic values",id:"schemas-and-dynamic-values",level:3},{value:"Remote function application",id:"remote-function-application",level:3},{value:"What is implemented as a Remote and what not?",id:"what-is-implemented-as-a-remote-and-what-not",level:3},{value:"Persistent variables and promises",id:"persistent-variables-and-promises",level:2},{value:"Executor state management",id:"executor-state-management",level:2},{value:"Transactions",id:"transactions",level:2},{value:"Scoping rules",id:"scoping-rules",level:2},{value:"Workflows",id:"workflows",level:3},{value:"Fibers",id:"fibers",level:3},{value:"Transactions",id:"transactions-1",level:3},{value:"Garbage collection",id:"garbage-collection",level:2}];function h(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"internals",children:"Internals"})}),"\n",(0,a.jsx)(n.p,{children:"This page contains information about some implementation details of ZIO Flow which are not necessary to know about for\nregular use of the system."}),"\n",(0,a.jsx)(n.h2,{id:"the-remote-type",children:"The Remote type"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"Remote"})," data type is a core concept in ZIO Flow. The most important feature a ",(0,a.jsx)(n.code,{children:"Remote"})," provides is that it can be\n",(0,a.jsx)(n.em,{children:"evaluated"}),". It is important to understand that evaluating a ",(0,a.jsx)(n.code,{children:"Remote[A]"})," does not produce a type of ",(0,a.jsx)(n.code,{children:"A"}),"!\nThe ",(0,a.jsx)(n.code,{children:"evaluateDynamic"})," function provides a ",(0,a.jsx)(n.code,{children:"DynamicValue"}),", which is a generic data type from ",(0,a.jsx)(n.code,{children:"zio-schema"}),".\nThis ",(0,a.jsx)(n.code,{children:"DynamicValue"})," must be something isomorphic to the ",(0,a.jsx)(n.code,{children:"A"})," type the remote value represents. So in case we have\na ",(0,a.jsx)(n.code,{children:"Schema[A]"})," we can convert this ",(0,a.jsx)(n.code,{children:"DynamicValue"})," back to a typed ",(0,a.jsx)(n.code,{children:"A"}),". ",(0,a.jsx)(n.code,{children:"Remote"})," itself contains a helper method\ncalled ",(0,a.jsx)(n.code,{children:".eval"})," that requires an implicit schema for ",(0,a.jsx)(n.code,{children:"A"})," and thus it returns with a typed value instead of\nthe ",(0,a.jsx)(n.code,{children:"DynamicValue"}),". This method is only used in special cases in the executor though, because the executor does not\nalways have a ",(0,a.jsx)(n.em,{children:"schema"})," for the values it is working with."]}),"\n",(0,a.jsx)(n.h3,{id:"schemas-and-dynamic-values",children:"Schemas and dynamic values"}),"\n",(0,a.jsxs)(n.p,{children:['This "limitation" allows us to work with user-defined types in ZIO Flow programs without the need to inject these types\ninto the server\'s classpath! Another reason is that we cannot serialize a ',(0,a.jsx)(n.code,{children:"Schema"})," that defines transformations via\nScala functions. If we just use the dynamic values on the server side we can run all the flow steps and only convert to\nactual typed representation when necessary."]}),"\n",(0,a.jsx)(n.p,{children:"There are three main cases when converting to typed value is required:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:['When a flow finishes running, the user may want to get a typed result. This is OK because it happens on the "client\nside" (where the flow is defined, not on the executor). This is the process where our custom types are defined so we\nhave the necessary ',(0,a.jsx)(n.code,{children:"Schema"})," to convert the dynamic result value to the expected one."]}),"\n",(0,a.jsxs)(n.li,{children:["When calling external services, for example using ",(0,a.jsx)(n.code,{children:"Operation.Http"}),", the serialization of the parameters like request\nbody needs to know its ",(0,a.jsx)(n.code,{children:"Schema"}),". This is a schema that is serialized as part of the flow, because it is used on the\nserver side. So this is ",(0,a.jsx)(n.em,{children:"not"})," the same schema that the client side has, but it is still necessary because it may\ncontain some additional information required for the serialization codec to produce the expected format."]}),"\n",(0,a.jsxs)(n.li,{children:['When performing some server-side operations that are "native". For example performing numerical operations is\nsomething that is implemented by calling the underlying Java implementation for those numeric operations. To do so, we\nneed to convert the ',(0,a.jsx)(n.code,{children:"DynamicValue"})," to the given numeric type to be able to call the native implementation."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Let's go through an example!"}),"\n",(0,a.jsx)(n.p,{children:"We define a case class with a schema:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-scala",children:"import zio.durationInt\nimport zio.flow._\nimport zio.flow.operation.http._\nimport zio.schema._\n\nfinal case class Example1(name: String, value: Int)\nobject Example1 {\n  implicit val schema = DeriveSchema.gen[Example1]\n}\n"})}),"\n",(0,a.jsxs)(n.p,{children:["then we store this as a ",(0,a.jsx)(n.code,{children:"Remote"})," value:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-scala",children:'val remote1 = Remote(Example1("something", 1))\n// remote1: Remote[Example1] = Literal(\n//   value = Record(\n//     id = Nominal(\n//       packageName = IndexedSeq("repl"),\n//       objectNames = IndexedSeq("MdocSession", "MdocApp"),\n//       typeName = "Example1"\n//     ),\n//     values = ListMap(\n//       "name" -> Primitive(value = "something", standardType = string),\n//       "value" -> Primitive(value = 1, standardType = int)\n//     )\n//   )\n// )\n'})}),"\n",(0,a.jsxs)(n.p,{children:["This will first convert the ",(0,a.jsx)(n.code,{children:"Example1"})," value to a ",(0,a.jsx)(n.code,{children:"DynamicValue"})," and then wrap it in a ",(0,a.jsx)(n.code,{children:"Remote.Literal"})," constructor.\nThis particular remote constructor does not store anything else than the dynamic value. The schema of ",(0,a.jsx)(n.code,{children:"Example1"})," is not\ntransferred to the executor. Evaluating it just returns the dynamic value itself. To call ",(0,a.jsx)(n.code,{children:".eval"})," and get\nback ",(0,a.jsx)(n.code,{children:"Example1"})," we need to provide the schema, which we only have on the definition side."]}),"\n",(0,a.jsxs)(n.p,{children:["Now let's assume that we have an ",(0,a.jsx)(n.em,{children:"activity"})," that requires an ",(0,a.jsx)(n.code,{children:"Example1"})," value as its input:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-scala",children:'val activity1: Activity[Example1, Unit] =\n  Activity(\n    "example activity",\n    "",\n    operation = Operation.Http(\n      host = "https://example.com",\n      API\n        .post("test")\n        .input[Example1]\n        .output[Unit]\n    ),\n    check = Activity.checkNotSupported,\n    compensate = Activity.compensateNotSupported\n  )\n'})}),"\n",(0,a.jsxs)(n.p,{children:["We can pass ",(0,a.jsx)(n.code,{children:"remote1"})," to ",(0,a.jsx)(n.code,{children:"activity1"})," to perform the HTTP request:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-scala",children:"val flow1 = activity1(remote1)\n"})}),"\n",(0,a.jsxs)(n.p,{children:["This translates to a ",(0,a.jsx)(n.code,{children:"ZFlow.RunActivity"})," value that connects a ",(0,a.jsx)(n.code,{children:"Remote"})," and an ",(0,a.jsx)(n.code,{children:"Activity"}),". The activity, however,\nthrough the ",(0,a.jsx)(n.code,{children:"operation"})," field, stores the input and output schema. This means that when we serialize ",(0,a.jsx)(n.code,{children:"flow1"}),", we also\nserialize ",(0,a.jsx)(n.code,{children:"Example1.schema"})," as part of it. Serializing a schema means converting it to a ",(0,a.jsx)(n.code,{children:"MetaSchema"}),", then on the\nserver side we deserialize a ",(0,a.jsx)(n.code,{children:"MetaSchema"})," and produce a ",(0,a.jsx)(n.code,{children:"Schema"})," from it. On the server side, however, we don't know\nanything about the ",(0,a.jsx)(n.code,{children:"Example1"})," Scala class at all! So the deserialized schema on the server side will be\na ",(0,a.jsx)(n.code,{children:"GenericRecord"}),", which stores its fields in a ",(0,a.jsx)(n.code,{children:"ListMap[String, _]"}),". That's a representation isomorphic to the original\ncase class, so the server can work with it."]}),"\n",(0,a.jsx)(n.h3,{id:"remote-function-application",children:"Remote function application"}),"\n",(0,a.jsxs)(n.p,{children:["Let's see how ",(0,a.jsx)(n.em,{children:"remote function application works"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"First we define a remote function as a regular Scala function:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-scala",children:"val f1 = (x: Remote[Int]) => x + 1 \n// f1: Remote[Int] => Remote[Int] = <function1>\n"})}),"\n",(0,a.jsxs)(n.p,{children:["This is not a serializable ",(0,a.jsx)(n.code,{children:"Remote"})," value yet, it is a Scala function. So we have to first convert it to\na ",(0,a.jsx)(n.code,{children:"Remote.UnboundRemoteFunction"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-scala",children:"val f2 = Remote.UnboundRemoteFunction.make(f1)\n// f2: Remote.UnboundRemoteFunction[Int, Int] = UnboundRemoteFunction(\n//   input = Unbound(identifier = ce0fdfae-90df-4cf5-b49d-c165ff9c1b2b),\n//   result = Binary(\n//     left = Unbound(identifier = ce0fdfae-90df-4cf5-b49d-c165ff9c1b2b),\n//     right = Literal(value = Primitive(value = 1, standardType = int)),\n//     operator = Numeric(\n//       operator = Add,\n//       numeric = zio.flow.remote.numeric.Numeric$NumericInt$@6533bc8e\n//     )\n//   )\n// )\n"})}),"\n",(0,a.jsxs)(n.p,{children:["This creates a ",(0,a.jsx)(n.code,{children:"Remote.Unbound"})," representing the unbound input parameter of the function, and ",(0,a.jsx)(n.em,{children:"calls"}),' the function with\nit, injecting this "hole" in our expression tree.']}),"\n",(0,a.jsxs)(n.p,{children:["Then we can ",(0,a.jsx)(n.em,{children:"bind"})," the parameter of this function by calling ",(0,a.jsx)(n.code,{children:".apply"})," on ",(0,a.jsx)(n.code,{children:"f2"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-scala",children:"val f3 = f2(100)\n// f3: Remote[Int] = Bind(\n//   unbound = Unbound(identifier = ce0fdfae-90df-4cf5-b49d-c165ff9c1b2b),\n//   value = Literal(value = Primitive(value = 100, standardType = int)),\n//   inner = Binary(\n//     left = Unbound(identifier = ce0fdfae-90df-4cf5-b49d-c165ff9c1b2b),\n//     right = Literal(value = Primitive(value = 1, standardType = int)),\n//     operator = Numeric(\n//       operator = Add,\n//       numeric = zio.flow.remote.numeric.Numeric$NumericInt$@6533bc8e\n//     )\n//   )\n// )\n"})}),"\n",(0,a.jsxs)(n.p,{children:["This way we get a ",(0,a.jsx)(n.code,{children:"Remote.Bind"})," which stores the parameter value (a ",(0,a.jsx)(n.code,{children:"Remote.Literal"})," holding ",(0,a.jsx)(n.code,{children:"100"}),")"]}),"\n",(0,a.jsx)(n.p,{children:"Let's see what happens when we evaluate this:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["First we evaluate the ",(0,a.jsx)(n.em,{children:"parameter value"})," and get a ",(0,a.jsx)(n.code,{children:"DynamicValue"})," back"]}),"\n",(0,a.jsxs)(n.li,{children:["Then we generate a ",(0,a.jsx)(n.em,{children:"fresh"})," ",(0,a.jsx)(n.code,{children:"RemoteVariableName"}),", a new ID that is guaranteed that was not used before"]}),"\n",(0,a.jsxs)(n.li,{children:["We store the parameter value in a ",(0,a.jsx)(n.em,{children:"remote variable"})," with this new ID. When this evaluation is part of a persistent\nflow execution, in this case the ",(0,a.jsx)(n.em,{children:"remote context"})," is not persisting the remote variable yet. It is just storing it in\nmemory."]}),"\n",(0,a.jsxs)(n.li,{children:["We push a ",(0,a.jsx)(n.em,{children:"binding"})," in the ",(0,a.jsx)(n.em,{children:"local context"}),". The local context belongs to a single remote evaluation, while the remote\ncontext for a whole persistent execution step. By pushing the local binding to the local context we are able to\nevaluate the ",(0,a.jsx)(n.code,{children:"Remote.Unbound"})," nodes."]}),"\n",(0,a.jsxs)(n.li,{children:["We evaluate the ",(0,a.jsx)(n.code,{children:"Bind"}),"'s inner remote, which is the ",(0,a.jsx)(n.code,{children:"UnboundRemoteFunction"}),". This is a remote expression tree which\nhas ",(0,a.jsx)(n.code,{children:"Remote.Unbound"})," in it, which we can now evaluate to the evaluated input because it is stored in the local\ncontext."]}),"\n",(0,a.jsx)(n.li,{children:"After that we remove the binding from the local context."}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["At this point we have a result of the applied function, but we are not done yet. It is possible that the ",(0,a.jsx)(n.em,{children:"result"})," of the\nfunction is a remote that captures the original ",(0,a.jsx)(n.code,{children:"Unbound"})," remote node, but the binding is only active during evaluating\nthis particular remote ",(0,a.jsx)(n.code,{children:"Bind"}),". So that would lead into an invalid continuation. To help imagine this situation, consider\nthis very simple and unusual example:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-scala",children:"val f4 = (x: Remote[Int]) => ZFlow.succeed(x)\n// f4: Remote[Int] => ZFlow[Any, zio.package.ZNothing, Int] = <function1>\n"})}),"\n",(0,a.jsxs)(n.p,{children:["This could be a function passed to a ",(0,a.jsx)(n.code,{children:"flatMap"})," in a ZIO Flow program."]}),"\n",(0,a.jsxs)(n.p,{children:["When we evaluate the function we just get back a new ",(0,a.jsx)(n.code,{children:"ZFlow"})," value, that refers to a ",(0,a.jsx)(n.code,{children:"Remote.Unbound"})," node (by using ",(0,a.jsx)(n.code,{children:"x"}),"\nin ",(0,a.jsx)(n.code,{children:"succeed"}),"). But the binding is only active during the actual function evaluation. So the solution ZIO Flow has is\nthat once we evaluated a function, we check if the ",(0,a.jsx)(n.em,{children:"result"})," refers to the input ",(0,a.jsx)(n.code,{children:"Unbound"})," identifier. All ",(0,a.jsx)(n.code,{children:"ZFlow"}),"\nand ",(0,a.jsx)(n.code,{children:"Remote"})," nodes are tracking their used variables so this does not require traversing the whole continuation. If it\ndoes not contain it, we are done. Otherwise we ",(0,a.jsx)(n.em,{children:"substitute"})," the ",(0,a.jsx)(n.code,{children:"Unbound"})," node in the result tree to the ",(0,a.jsx)(n.em,{children:"remote\nvariable"})," we generated. This way we moved out the local binding to be a persisted binding, as remote variables are\npersisted; now it can be accessed in the continuation safely, even if the executor restarts."]}),"\n",(0,a.jsx)(n.h3,{id:"what-is-implemented-as-a-remote-and-what-not",children:"What is implemented as a Remote and what not?"}),"\n",(0,a.jsxs)(n.p,{children:["There are many ",(0,a.jsx)(n.code,{children:"Remote"})," constructors for some primitive operations we support, but there are even more functionalities\nimplemented in other classes, such as ",(0,a.jsx)(n.code,{children:"BinaryOperators"}),", ",(0,a.jsx)(n.code,{children:"RemoteConversions"}),", etc. The primary distinction is that if\nsomething can be implemented by staying on the level of ",(0,a.jsx)(n.code,{children:"DynamicValue"}),"s, it is a ",(0,a.jsx)(n.code,{children:"Remote"})," constructor. If the\ncalculation requires converting the dynamic values to some typed value first, it is implemented in one of the supporting\nclasses such as the ones mentioned above."]}),"\n",(0,a.jsx)(n.h2,{id:"persistent-variables-and-promises",children:"Persistent variables and promises"}),"\n",(0,a.jsxs)(n.p,{children:["From the ZIO Flow program's perspective a persistent variables has a name typed as ",(0,a.jsx)(n.code,{children:"RemoteVariableName"}),", which is just a\nwrapper over ",(0,a.jsx)(n.code,{children:"String"}),". The name used to store the variable in the ",(0,a.jsx)(n.em,{children:"key-value store"})," is derived from this name but\ncontains more information."]}),"\n",(0,a.jsxs)(n.p,{children:["Each variable is defined in a given ",(0,a.jsx)(n.a,{href:"#scoping-rules",children:"scope"}),". In short, the scope identifies the flow/fiber/transaction\nthe variable was defined in. When accessing a remote variable there are scoping rules (defined below) defining how\nvariables can be accessed from parent scopes."]}),"\n",(0,a.jsxs)(n.p,{children:["The actual variable name used for storing the variable is described by ",(0,a.jsx)(n.code,{children:"ScopedRemoteVariableName"}),", which associates\na ",(0,a.jsx)(n.code,{children:"RemoteVariableScope"})," with a ",(0,a.jsx)(n.code,{children:"RemoteVariableName"}),". The ",(0,a.jsx)(n.em,{children:"key"})," has to be invertible\nfor ",(0,a.jsx)(n.a,{href:"#garbage-collection",children:"garbage collection"})," to be able to identify all the stored variables."]}),"\n",(0,a.jsxs)(n.p,{children:["The persistent executor is not storing the variables directly using the ",(0,a.jsx)(n.code,{children:"KeyValueStore"})," interface, but uses a wrapper on\ntop of it called ",(0,a.jsx)(n.code,{children:"RemoteVariableKeyValueStore"}),". This wrapper is responsible for dealing with the scoping rules,\npublishing change events for watched variables, and to handle ",(0,a.jsx)(n.em,{children:"timestamps"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:["Each variable has a timestamp. Setting a new value for a remote variable does not overwrite the old value, but instead\nwrites a new value with a new timestamp. Timestamps are essential for ",(0,a.jsx)(n.a,{href:"#transactions",children:"transactions"})," to be able to detect\nconflicts in accessing the variables. The Timestamp values are coming from a ",(0,a.jsx)(n.em,{children:"virtual clock"})," which is basically\nincrementing at each flow step. Forked flows inherit the current parent timestamp. In case a forked flow is joined, the\nparent fiber's virtual clock will be advanced to the maximum of the parent and the child fiber's clock."]}),"\n",(0,a.jsx)(n.h2,{id:"executor-state-management",children:"Executor state management"}),"\n",(0,a.jsxs)(n.p,{children:["The persistent executor persists its state and any new/changed persisted remote variables after each ",(0,a.jsx)(n.em,{children:"step"}),". One step is\nthe processing of one ",(0,a.jsx)(n.code,{children:"ZFlow"})," instruction."]}),"\n",(0,a.jsxs)(n.p,{children:["While processing the step the executor collects a sequence of ",(0,a.jsx)(n.code,{children:"StateChange"})," values. At the end of each execution step\nthe following major steps are performed:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["applying the ",(0,a.jsx)(n.code,{children:"StateChange"})," changes to the executor's state (in memory)"]}),"\n",(0,a.jsx)(n.li,{children:"collecting the remote variables which were accessed (read or modified) during the step"}),"\n",(0,a.jsx)(n.li,{children:"saving the modified persistent variables to the key-value store"}),"\n",(0,a.jsxs)(n.li,{children:["applying some more ",(0,a.jsx)(n.code,{children:"StateChange"})," values to the executor's state, like recording the modified variables and advancing\nthe virtual clock"]}),"\n",(0,a.jsx)(n.li,{children:"persisting the new executor's state to the key-value store"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["Currently after each step we save a the full executor state into the key-value store. This is not optimal, but the\nexecutor is designed in a way by working with ",(0,a.jsx)(n.code,{children:"StateChange"})," values that in the future it is going to support saving only\nthe changes into a journal instead."]}),"\n",(0,a.jsx)(n.h2,{id:"transactions",children:"Transactions"}),"\n",(0,a.jsx)(n.p,{children:"In transactions every time a variable is accessed, it's current timestamp gets recorded. When the transaction is\ncommitted, these timestamps are compared to the actual timestamps and in case there is a difference that means there is\na conflict and the transaction has to be retried."}),"\n",(0,a.jsxs)(n.p,{children:["Retry can also be triggered by the ",(0,a.jsx)(n.code,{children:"retryUntil"})," operator - it is implemented as special kind of failure. In fact within\na\ntransaction each user error ",(0,a.jsx)(n.code,{children:"E"})," is wrapped in a ",(0,a.jsx)(n.code,{children:"TransactionalFailure[E] = UserError[E] | Retry"})," type."]}),"\n",(0,a.jsxs)(n.p,{children:["Retry can be captured by the ",(0,a.jsx)(n.code,{children:"orTry"})," operator in which case it works exactly like handling an error with ",(0,a.jsx)(n.code,{children:"Fold"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:["In case the retry is not handled when it reaches a ",(0,a.jsx)(n.code,{children:"CommitTransaction"})," instruction in the stack, the transaction gets\nrestarted."]}),"\n",(0,a.jsxs)(n.p,{children:["Retrying or failing in a transaction also causes all the ",(0,a.jsx)(n.em,{children:"activities"})," to get compensated by running their compensate\nflows in reverse order."]}),"\n",(0,a.jsx)(n.h2,{id:"scoping-rules",children:"Scoping rules"}),"\n",(0,a.jsx)(n.h3,{id:"workflows",children:"Workflows"}),"\n",(0,a.jsx)(n.p,{children:"A top level workflow defines the top level scope by its unique flow identifier. This guarantees that:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"separate workflows cannot see each other's variables"}),"\n",(0,a.jsx)(n.li,{children:"restarted workflows see the same set of variables as the previous run as\nthey share the flow id"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Operation semantics on the top level of workflows (not in a forked fiber and\nnot in an active transaction):"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["New(name): creates a new remote variable in the KV store's variable\nnamespace called ",(0,a.jsx)(n.code,{children:'"$flowid__$name"'})]}),"\n",(0,a.jsxs)(n.li,{children:["Get(name): reads ",(0,a.jsx)(n.code,{children:'"$flowid__$name"'})]}),"\n",(0,a.jsxs)(n.li,{children:["Set(name): writes ",(0,a.jsx)(n.code,{children:'"$flowid__$name"'})]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"fibers",children:"Fibers"}),"\n",(0,a.jsxs)(n.p,{children:["Forked workflows are like regular workflows but they are not individually submitted, instead created by the executor by\nthe Fork operator. Each workflow maintains a fork counter and generates new workflow ids based\non that. So a forked workflow's flow identifier will be\n",(0,a.jsx)(n.code,{children:'"$parentId_fork$parentForkCounter"'}),"."]}),"\n",(0,a.jsx)(n.p,{children:"Desired semantics:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Forked workflows should have read/write access to variables accessible to\nthe parent workflow"}),"\n",(0,a.jsx)(n.li,{children:"Creating new variables in a forked workflow should not be accessible to\nthe parent and sibling workflows"}),"\n",(0,a.jsx)(n.li,{children:"Parallel forked workflows should be able to create independent variables\nwith the same name"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Operation semantics in forked workflows:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["New(name): creates a new remote variable in the KV store's variable\nnamespace prefixed by the active workflow identifier ",(0,a.jsx)(n.code,{children:'"$flowid__$name"'}),"\n(which is ",(0,a.jsx)(n.code,{children:'"$parentId_fork$parentForkCounter__$$name"'}),")."]}),"\n",(0,a.jsxs)(n.li,{children:["Get(name): first finds the variable's scope by first looking in the\ncurrent fiber's scope (using ",(0,a.jsx)(n.code,{children:'"$flowid__$name"'}),") - if it does not\nexist, it recursively tries to access the variable in the parent scope\n(",(0,a.jsx)(n.code,{children:'"$parentid__$name"'}),")."]}),"\n",(0,a.jsx)(n.li,{children:"Set(name): same lookup as for Get - Get and Set must always select the\nsame variable in an executor step"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"transactions-1",children:"Transactions"}),"\n",(0,a.jsx)(n.p,{children:"In transactions we have to delay the effect of Set (but within the\ntransaction still see that value in Get) until the transaction is committed.\nThis means that we need to store values for the same remote variable name per\ntransaction beside its original value - which means transactions define their\nown scope."}),"\n",(0,a.jsx)(n.p,{children:"Desired semantics:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Creating a new variable in a transaction: should not behave differently\nthan in a regular scope","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:'transactional variable updates are only interesting if there are\nmultiple fibers running transactions modifying the same variable. This\nmeans that even if there are "colliding" new variables in parallel\ntransactions, their parent scope will be different (because fibers are\nalso defining scopes) so they would never collide.'}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.li,{children:"Within the transaction, Get and Set should work as usual, but the effect\nof Set should not be visible for other fibers, even if the changed\nvariable is in a shared scope."}),"\n",(0,a.jsx)(n.li,{children:"When the transaction is committed, the changes are either applied to\nthese shared variables, or the transaction gets reverted."}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["Flow state contains a transaction counter that can be used as a unique\nidentifier for transaction scopes, similar to how fiber scopes are generated:\n",(0,a.jsx)(n.code,{children:'"parentId_tx$transactionCounter"'}),"."]}),"\n",(0,a.jsx)(n.p,{children:"Operation semantics in transaction scopes:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"New(name): creates a new remote variable in the parent scope"}),"\n",(0,a.jsx)(n.li,{children:"Get(name): acts the same way as in forked workflows, but also records the\naccessed variable's version if necessary"}),"\n",(0,a.jsxs)(n.li,{children:["Set(name): always sets the value in the transaction scope\n(",(0,a.jsx)(n.code,{children:"$parentid__$name"}),")"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"garbage-collection",children:"Garbage collection"}),"\n",(0,a.jsx)(n.p,{children:"The garbage collector of the persisted executor runs periodically and performs the following steps:"}),"\n",(0,a.jsx)(n.p,{children:"First we get all the persisted remote variables from the key-value store. The encoding of scopes in the variable names\nis invertible so we can recover a set of scoped remote variable names by scanning the keys."}),"\n",(0,a.jsx)(n.p,{children:"For each running flow we gather the known set of remote variables referenced by the remaining of that flow. For this we\nget each flow's state and get the referenced remote variables from it's current stack (variable usage is already tracked\non ZFlow and Remote level)."}),"\n",(0,a.jsxs)(n.p,{children:["Because of how variable ",(0,a.jsx)(n.a,{href:"#scoping-rules",children:"scoping"})," works, we don't know in the GC in advance exactly which scoped remote\nvariable a given\nremote variable name refers to - it is possible that a fiber refers to its parent fiber's remote variable, etc."]}),"\n",(0,a.jsxs)(n.p,{children:["Transactions are also generating scoped variables. To work around this the garbage collector is following a pessimistic\nbut safe logic: if a flow refers to variable A, it prevents the removal of A from that flow and all its parent flows.\nFor\nvariables with transactional scope, we know them from the list of all existing scoped remote variables, and we simply\nkeep all of them belonging to the flow where the referenced name is coming from. So if flow X references variable A and\nin the key-value store we have two variables with name A in scope ",(0,a.jsx)(n.code,{children:"X/transaction1"})," and ",(0,a.jsx)(n.code,{children:"X/transaction2"})," we simply keep\nboth."]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var i=t(96540);const a={},s=i.createContext(a);function r(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);