"use strict";(self.webpackChunkzio_site=self.webpackChunkzio_site||[]).push([[52216],{23885:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"zio-kafka/index","title":"Getting Started with ZIO Kafka","description":"ZIO Kafka is a Kafka client for ZIO. It provides a purely functional, streams-based interface to the Kafka","source":"@site/docs/zio-kafka/index.md","sourceDirName":"zio-kafka","slug":"/zio-kafka/","permalink":"/zio-kafka/","draft":false,"unlisted":false,"editUrl":"https://github.com/zio/zio/edit/series/2.x/docs/zio-kafka/index.md","tags":[],"version":"current","frontMatter":{"id":"index","title":"Getting Started with ZIO Kafka","sidebar_label":"Getting Started"},"sidebar":"ecosystem-sidebar","previous":{"title":"Scalaz 7.x Interop","permalink":"/zio-json/interop/scalaz-7x"},"next":{"title":"Creating a zio-kafka Consumer","permalink":"/zio-kafka/creating-a-consumer"}}');var s=n(74848),r=n(28453);const t={id:"index",title:"Getting Started with ZIO Kafka",sidebar_label:"Getting Started"},o=void 0,l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Features",id:"features",level:2},{value:"Getting started",id:"getting-started",level:2},{value:"Example",id:"example",level:2},{value:"Resources",id:"resources",level:2},{value:"Articles",id:"articles",level:3},{value:"Video",id:"video",level:3},{value:"Example projects",id:"example-projects",level:3},{value:"Adopters",id:"adopters",level:2},{value:"Performance",id:"performance",level:2},{value:"Developers",id:"developers",level:2}];function d(e){const a={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.a,{href:"https://github.com/zio/zio-kafka",children:"ZIO Kafka"})," is a Kafka client for ZIO. It provides a purely functional, streams-based interface to the Kafka\nclient and integrates effortlessly with ZIO and zio-streams. Often zio-kafka programs have a ",(0,s.jsx)(a.em,{children:"higher"})," throughput than\nprograms that use the Java Kafka client directly (see section ",(0,s.jsx)(a.a,{href:"#performance",children:"Performance"})," below)."]}),"\n",(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.a,{href:"https://github.com/zio/zio/wiki/Project-Stages",children:(0,s.jsx)(a.img,{src:"https://img.shields.io/badge/Project%20Stage-Production%20Ready-brightgreen.svg",alt:"Production Ready"})})," ",(0,s.jsx)(a.img,{src:"https://github.com/zio/zio-kafka/workflows/CI/badge.svg",alt:"CI Badge"})," ",(0,s.jsx)(a.a,{href:"https://oss.sonatype.org/content/repositories/releases/dev/zio/zio-kafka_2.13/",children:(0,s.jsx)(a.img,{src:"https://img.shields.io/nexus/r/https/oss.sonatype.org/dev.zio/zio-kafka_2.13.svg?label=Sonatype%20Release",alt:"Sonatype Releases"})})," ",(0,s.jsx)(a.a,{href:"https://oss.sonatype.org/content/repositories/snapshots/dev/zio/zio-kafka_2.13/",children:(0,s.jsx)(a.img,{src:"https://img.shields.io/nexus/s/https/oss.sonatype.org/dev.zio/zio-kafka_2.13.svg?label=Sonatype%20Snapshot",alt:"Sonatype Snapshots"})})," ",(0,s.jsx)(a.a,{href:"https://javadoc.io/doc/dev.zio/zio-kafka-docs_2.13",children:(0,s.jsx)(a.img,{src:"https://javadoc.io/badge2/dev.zio/zio-kafka-docs_2.13/javadoc.svg",alt:"javadoc"})})," ",(0,s.jsx)(a.a,{href:"https://github.com/zio/zio-kafka",children:(0,s.jsx)(a.img,{src:"https://img.shields.io/github/stars/zio/zio-kafka?style=social",alt:"ZIO Kafka"})})," ",(0,s.jsx)(a.a,{href:"https://scala-steward.org",children:(0,s.jsx)(a.img,{src:"https://img.shields.io/badge/Scala_Steward-helping-blue.svg?style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAQCAMAAAARSr4IAAAAVFBMVEUAAACHjojlOy5NWlrKzcYRKjGFjIbp293YycuLa3pYY2LSqql4f3pCUFTgSjNodYRmcXUsPD/NTTbjRS+2jomhgnzNc223cGvZS0HaSD0XLjbaSjElhIr+AAAAAXRSTlMAQObYZgAAAHlJREFUCNdNyosOwyAIhWHAQS1Vt7a77/3fcxxdmv0xwmckutAR1nkm4ggbyEcg/wWmlGLDAA3oL50xi6fk5ffZ3E2E3QfZDCcCN2YtbEWZt+Drc6u6rlqv7Uk0LdKqqr5rk2UCRXOk0vmQKGfc94nOJyQjouF9H/wCc9gECEYfONoAAAAASUVORK5CYII=",alt:"Scala Steward badge"})})]}),"\n",(0,s.jsx)(a.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(a.p,{children:"Apache Kafka is a distributed event streaming platform that acts as a distributed publish-subscribe messaging system. It enables us to build distributed streaming data pipelines and event-driven applications."}),"\n",(0,s.jsx)(a.p,{children:"Kafka has a mature Java client for producing and consuming events, but it has a low-level API. Zio-kafka is a ZIO native client for Apache Kafka. It has a high-level streaming API on top of the Java client. So we can produce and consume events using the declarative concurrency model of zio-streams. In addition, zio-kafka supports an even higher level API where you only write the processing part and the rest is handled by zio-kafka."}),"\n",(0,s.jsx)(a.h2,{id:"features",children:"Features"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"Exposes the Java Kafka consumer, producer and admin clients with a ZIO based interface."}),"\n",(0,s.jsxs)(a.li,{children:["Consuming:","\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"2 APIs: streaming and ZIO workflow based"}),"\n",(0,s.jsx)(a.li,{children:"supports custom deserialization"}),"\n",(0,s.jsx)(a.li,{children:"process each partition in parallel for highest throughput"}),"\n",(0,s.jsx)(a.li,{children:"allows batched processing for highest throughput"}),"\n",(0,s.jsx)(a.li,{children:"configurable per partition pre-fetching (with back-pressure)"}),"\n",(0,s.jsxs)(a.li,{children:["the only async Kafka consumer ",(0,s.jsx)(a.a,{href:"https://zio.dev/zio-kafka/preventing-duplicates",children:"without duplicates"})," after a rebalance (as far as we know)"]}),"\n",(0,s.jsx)(a.li,{children:"very configurable"}),"\n",(0,s.jsx)(a.li,{children:"automatic or manual starting offset"}),"\n",(0,s.jsx)(a.li,{children:"supports external commits"}),"\n",(0,s.jsx)(a.li,{children:"retries after authentication/authorization errors"}),"\n",(0,s.jsx)(a.li,{children:"exposes metrics"}),"\n",(0,s.jsx)(a.li,{children:"diagnostics API"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["Producing:","\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"2 APIs: streaming and ZIO workflow based"}),"\n",(0,s.jsx)(a.li,{children:"supports custom serialization"}),"\n",(0,s.jsx)(a.li,{children:"allows for batches for highest throughput"}),"\n",(0,s.jsx)(a.li,{children:"optionally await broker acknowledgements"}),"\n",(0,s.jsx)(a.li,{children:"optional retries after authentication/authorization errors"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["Admin API:","\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"exposes all the admin client methods with a ZIO based interface"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["Proper errors when broker expects SSL (no ",(0,s.jsx)(a.a,{href:"https://issues.apache.org/jira/browse/KAFKA-4090",children:"OOM crashes"}),")"]}),"\n",(0,s.jsx)(a.li,{children:"Test kit with embedded kafka broker"}),"\n",(0,s.jsx)(a.li,{children:"Well documented"}),"\n",(0,s.jsxs)(a.li,{children:["Community support via ",(0,s.jsx)(a.a,{href:"https://discord.com/channels/629491597070827530/629497941719121960",children:"Discord"})]}),"\n",(0,s.jsxs)(a.li,{children:["Commercial support via ",(0,s.jsx)(a.a,{href:"https://www.ziverge.com",children:"Ziverge"})]}),"\n"]}),"\n",(0,s.jsx)(a.h2,{id:"getting-started",children:"Getting started"}),"\n",(0,s.jsxs)(a.p,{children:["See the ",(0,s.jsx)(a.a,{href:"https://zio.dev/guides/tutorials/producing-consuming-data-from-kafka-topics/",children:"zio-kafka tutorial"})," for a grand tour of the different ways you can use zio-kafka."]}),"\n",(0,s.jsxs)(a.p,{children:["In order to use this library, we need to add the following line in our ",(0,s.jsx)(a.code,{children:"build.sbt"})," file:"]}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-scala",children:'libraryDependencies += "dev.zio" %% "zio-kafka"         % "2.11.0"\nlibraryDependencies += "dev.zio" %% "zio-kafka-testkit" % "2.11.0" % Test\n'})}),"\n",(0,s.jsxs)(a.p,{children:["Snapshots are available on Sonatype's snapshot repository ",(0,s.jsx)(a.a,{href:"https://oss.sonatype.org/content/repositories/snapshots",children:"https://oss.sonatype.org/content/repositories/snapshots"}),".\n",(0,s.jsx)(a.a,{href:"https://oss.sonatype.org/content/repositories/snapshots/dev/zio/zio-kafka_3/",children:"Browse here"})," to find available versions."]}),"\n",(0,s.jsxs)(a.p,{children:["For ",(0,s.jsx)(a.code,{children:"zio-kafka-testkit"})," together with Scala 3, you also need to add the following to your ",(0,s.jsx)(a.code,{children:"build.sbt"})," file:"]}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-scala",children:'excludeDependencies += "org.scala-lang.modules" % "scala-collection-compat_2.13"\n'})}),"\n",(0,s.jsx)(a.h2,{id:"example",children:"Example"}),"\n",(0,s.jsxs)(a.p,{children:["Let's write a simple Kafka producer and consumer using zio-kafka with zio-streams. Before everything, we need a running instance of Kafka. We can do that by saving the following docker-compose script in the ",(0,s.jsx)(a.code,{children:"docker-compose.yml"})," file and run ",(0,s.jsx)(a.code,{children:"docker compose up"}),":"]}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-docker-compose",children:'services:\n  broker:\n    image: apache/kafka:3.9.0\n    container_name: broker\n    ports:\n      - "9092:9092"\n    environment:\n      KAFKA_NODE_ID: 1\n      KAFKA_BROKER_ID: 1\n      KAFKA_PROCESS_ROLES: broker,controller\n      KAFKA_LISTENERS: PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092\n      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT\n      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker:29093\n      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1\n      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1\n      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0\n      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT\n'})}),"\n",(0,s.jsx)(a.p,{children:"Now, we can run our ZIO Kafka Streaming application:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-scala",children:'import zio._\nimport zio.kafka.consumer._\nimport zio.kafka.producer.{ Producer, ProducerSettings }\nimport zio.kafka.serde._\nimport zio.stream.ZStream\n\nobject ReadmeExample extends ZIOAppDefault {\n\n  private val producerRun: ZIO[Any, Throwable, Unit] =\n    ZIO.scoped {\n      for {\n        producer <-\n          Producer.make(\n            ProducerSettings(List("localhost:9092"))\n          )\n        _ <- ZStream\n          .fromSchedule(Schedule.fixed(2.seconds))\n          .mapZIO(_ => Random.nextIntBetween(0, Int.MaxValue))\n          .mapZIO { random =>\n            producer.produce[Any, Long, String](\n              topic = "random-topic",\n              key = (random % 4).toLong,\n              value = random.toString,\n              keySerializer = Serde.long,\n              valueSerializer = Serde.string\n            )\n          }\n          .runDrain\n      } yield ()\n    }\n\n  private val consumerRun: ZIO[Any, Throwable, Unit] =\n    ZIO.scoped {\n      for {\n        consumer <-\n          Consumer.make(\n            ConsumerSettings(List("localhost:9092"))\n              .withGroupId("group")\n          )\n        _ <- consumer\n          .plainStream(Subscription.topics("random"), Serde.long, Serde.string)\n          .tap(r => Console.printLine(r.value))\n          .map(_.offset)\n          .aggregateAsync(Consumer.offsetBatches)\n          .mapZIO(_.commit)\n          .runDrain\n      } yield ()\n    }\n\n  override def run: ZIO[Any, Throwable, Unit] =\n    ZIO.raceFirst(producerRun, List(consumerRun))\n}\n'})}),"\n",(0,s.jsx)(a.h2,{id:"resources",children:"Resources"}),"\n",(0,s.jsx)(a.h3,{id:"articles",children:"Articles"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://zio.dev/guides/tutorials/producing-consuming-data-from-kafka-topics/",children:"ZIO Kafka tutorial"})," by the zio-kafka team"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://day-to-day-stuff.blogspot.com/2024/12/zio-kafka-faster-than-java-kafka.html",children:"ZIO Kafka faster than Java Kafka"})," by Erik van Oosten (December 2024)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.baeldung.com/scala/zio-kafka-intro",children:"Introduction to zio-kafka"})," by Stefanos Georgakis, Baeldung (January 2023)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://scalac.io/blog/streaming-microservices-with-zio-and-kafka/",children:"How to implement streaming microservices with ZIO 2 and Kafka"})," by Jorge Vasquez, Scalac (June 2023)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://medium.com/@knoldus/zio-kafka-d865fc20174a",children:"Zio Kafka"})," by Knoldus Inc (January 2022)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://pramodshehan.medium.com/writing-a-simple-producer-and-consumer-using-zio-workflows-a57def08210c",children:"Writing a Simple Producer and Consumer Using ZIO Workflows"})," by Pramod Shehan (December 2022)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.ziverge.com/post/zio-kafka-with-transactions---a-debugging-story/",children:"ZIO Kafka with transactions - a debugging story"})," by Daniel Vigovszky, Ziverge (June 2022)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://blog.knoldus.com/introduction-to-zio-kafka/",children:"Introduction to Zio-Kafka"})," by Akash Kumar (March 2022)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://blog.nashtechglobal.com/introduction-to-zio-kafka/",children:"Introduction to Zio-Kafka"})," by Khalid Ahmed, Nash Tech (March 2022)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://rockthejvm.com/articles/zio-kafka/",children:"ZIO Kafka: A Practical Streaming Tutorial"})," by Riccardo Cardin, Rock the JVM (August 2021)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://functional.works-hub.com/learn/using-zio-kafka-with-offset-storage-in-postgres-for-transactional-processing-be4a2",children:"Using ZIO Kafka with offset storage in Postgres for transactional processing"})," by Marek Kadek (March 2021)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://scalac.io/streaming-microservices-with-zio-and-kafka/",children:"Streaming microservices with ZIO and Kafka"})," by Aleksandar Skrbic (February 2021)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.ziverge.com/post/an-introduction-to-zio-kafka/",children:"An Introduction to ZIO Kafka"})," by Ziverge (April 2020)"]}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"video",children:"Video"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.youtube.com/watch?v=McnC2UU-RIE",children:"Optimizing Data Transfer Kafka to BQ: let's use Scala to make it custom"})," by Dario Amorosi, Adevinta (November 2024)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.youtube.com/watch?v=MJoRwEyyVxM",children:"Making ZIO-Kafka Safer and Faster in 2023"})," by Erik van Oosten (November 2023)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.youtube.com/watch?v=ExFjjczwwHs",children:"ZIO Kafka with Scala: A Tutorial"})," by Rock the JVM (August 2021)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.youtube.com/watch?v=GECv1ONieLw",children:"ZIO WORLD - ZIO Kafka"})," by Aleksandar Skrbic (March 2020) \u2014 Aleksandar Skrbic presented ZIO Kafka, a critical library for the modern Scala developer, which hides some of the complexities of Kafka."]}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"example-projects",children:"Example projects"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://github.com/adevinta/kafka-bigquery-express/",children:"Kafka BigQuery Express"}),' by Adevinta (November 2024) A production system to copy data from Kafka to BigQuery, safely and cost-effectively. (See also the video "Optimizing Data Transfer...".)']}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://github.com/ScalaConsultants/zio-kafka-showcase",children:"zio-kafka-showcase"})," by Jorge V\xe1squez, Example project that demonstrates how to build Kafka based microservices with Scala and ZIO"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://github.com/pramodShehan5/zio-kafka-demo1",children:"zio-kafka-demo1"})," (December 2022), example consumer and producer using zio-kafka 2.0.5"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://github.com/zivergetech/zio-kafka-example-app",children:"zio-kafka-example-app"})," by Ziverge (December 2020), example application using zio-kafka 0.8.0"]}),"\n"]}),"\n",(0,s.jsx)(a.h2,{id:"adopters",children:"Adopters"}),"\n",(0,s.jsx)(a.p,{children:"Here is a partial list of companies using zio-kafka in production."}),"\n",(0,s.jsxs)(a.p,{children:["Want to see your company here? ",(0,s.jsx)(a.a,{href:"https://github.com/zio/zio-kafka/edit/master/docs/index.md",children:"Submit a PR"}),"!"]}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:(0,s.jsx)(a.a,{href:"https://www.conduktor.io",children:"Conduktor"})}),"\n",(0,s.jsx)(a.li,{children:(0,s.jsx)(a.a,{href:"https://www.kelkoogroup.com",children:"KelkooGroup"})}),"\n",(0,s.jsx)(a.li,{children:(0,s.jsx)(a.a,{href:"https://rocker.com",children:"Rocker"})}),"\n"]}),"\n",(0,s.jsx)(a.h2,{id:"performance",children:"Performance"}),"\n",(0,s.jsxs)(a.p,{children:["Often, ",(0,s.jsx)(a.em,{children:"zio-kafka programs consume with a higher throughput"})," than programs that use the java-kafka client directly.\nRead on for the details."]}),"\n",(0,s.jsxs)(a.p,{children:["By default, zio-kafka programs process partitions in parallel. The default java-kafka client does not provide parallel\nprocessing. Of course, there is some overhead in buffering records and distributing them to the fibers that need them.\nOn 2024-11-23, we estimated that zio-kafka consumes faster than the java-kafka client when processing takes more than\n~1.2ms per 1000 records. The precise time depends on many factors. Please\nsee ",(0,s.jsx)(a.a,{href:"https://day-to-day-stuff.blogspot.com/2024/12/zio-kafka-faster-than-java-kafka.html",children:"this article"})," for more\ndetails."]}),"\n",(0,s.jsx)(a.p,{children:"If you do not care for the convenient ZStream based API that zio-kafka brings, and latency is of absolute importance,\nusing the java based Kafka client directly is still the better choice."}),"\n",(0,s.jsx)(a.h2,{id:"developers",children:"Developers"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:(0,s.jsx)(a.a,{href:"https://github.com/zio/zio-kafka/blob/master/zio-kafka-bench/README.md",children:"Benchmarks and Flame graphs"})}),"\n"]})]})}function h(e={}){const{wrapper:a}={...(0,r.R)(),...e.components};return a?(0,s.jsx)(a,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,a,n)=>{n.d(a,{R:()=>t,x:()=>o});var i=n(96540);const s={},r=i.createContext(s);function t(e){const a=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function o(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),i.createElement(r.Provider,{value:a},e.children)}}}]);