"use strict";(self.webpackChunkzio_site=self.webpackChunkzio_site||[]).push([[52216],{23885:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"zio-kafka/index","title":"Getting Started with ZIO Kafka","description":"ZIO Kafka is a Kafka client for ZIO. It provides a purely functional, streams-based interface to the Kafka","source":"@site/docs/zio-kafka/index.md","sourceDirName":"zio-kafka","slug":"/zio-kafka/","permalink":"/zio-kafka/","draft":false,"unlisted":false,"editUrl":"https://github.com/zio/zio/edit/series/2.x/docs/zio-kafka/index.md","tags":[],"version":"current","frontMatter":{"id":"index","title":"Getting Started with ZIO Kafka","sidebar_label":"Getting Started"},"sidebar":"ecosystem-sidebar","previous":{"title":"Scalaz 7.x Interop","permalink":"/zio-json/interop/scalaz-7x"},"next":{"title":"Consuming Kafka topics using ZIO Streams","permalink":"/zio-kafka/consuming-kafka-topics-using-zio-streams"}}');var s=n(74848),t=n(28453);const o={id:"index",title:"Getting Started with ZIO Kafka",sidebar_label:"Getting Started"},r=void 0,c={},l=[{value:"Introduction",id:"introduction",level:2},{value:"Installation",id:"installation",level:2},{value:"Example",id:"example",level:2},{value:"Resources",id:"resources",level:2},{value:"Articles",id:"articles",level:3},{value:"Video",id:"video",level:3},{value:"Example projects",id:"example-projects",level:3},{value:"Adopters",id:"adopters",level:2},{value:"Performance",id:"performance",level:2}];function d(e){const a={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.a,{href:"https://github.com/zio/zio-kafka",children:"ZIO Kafka"})," is a Kafka client for ZIO. It provides a purely functional, streams-based interface to the Kafka\nclient and integrates effortlessly with ZIO and ZIO Streams. Often zio-kafka programs have a ",(0,s.jsx)(a.em,{children:"higher"})," throughput than\nprograms that use the Java Kafka client directly (see section ",(0,s.jsx)(a.a,{href:"#performance",children:"Performance"})," below)."]}),"\n",(0,s.jsxs)(a.p,{children:[(0,s.jsx)(a.a,{href:"https://github.com/zio/zio/wiki/Project-Stages",children:(0,s.jsx)(a.img,{src:"https://img.shields.io/badge/Project%20Stage-Production%20Ready-brightgreen.svg",alt:"Production Ready"})})," ",(0,s.jsx)(a.img,{src:"https://github.com/zio/zio-kafka/workflows/CI/badge.svg",alt:"CI Badge"})," ",(0,s.jsx)(a.a,{href:"https://oss.sonatype.org/content/repositories/releases/dev/zio/zio-kafka_2.13/",children:(0,s.jsx)(a.img,{src:"https://img.shields.io/nexus/r/https/oss.sonatype.org/dev.zio/zio-kafka_2.13.svg?label=Sonatype%20Release",alt:"Sonatype Releases"})})," ",(0,s.jsx)(a.a,{href:"https://oss.sonatype.org/content/repositories/snapshots/dev/zio/zio-kafka_2.13/",children:(0,s.jsx)(a.img,{src:"https://img.shields.io/nexus/s/https/oss.sonatype.org/dev.zio/zio-kafka_2.13.svg?label=Sonatype%20Snapshot",alt:"Sonatype Snapshots"})})," ",(0,s.jsx)(a.a,{href:"https://javadoc.io/doc/dev.zio/zio-kafka-docs_2.13",children:(0,s.jsx)(a.img,{src:"https://javadoc.io/badge2/dev.zio/zio-kafka-docs_2.13/javadoc.svg",alt:"javadoc"})})," ",(0,s.jsx)(a.a,{href:"https://github.com/zio/zio-kafka",children:(0,s.jsx)(a.img,{src:"https://img.shields.io/github/stars/zio/zio-kafka?style=social",alt:"ZIO Kafka"})})," ",(0,s.jsx)(a.a,{href:"https://scala-steward.org",children:(0,s.jsx)(a.img,{src:"https://img.shields.io/badge/Scala_Steward-helping-blue.svg?style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAQCAMAAAARSr4IAAAAVFBMVEUAAACHjojlOy5NWlrKzcYRKjGFjIbp293YycuLa3pYY2LSqql4f3pCUFTgSjNodYRmcXUsPD/NTTbjRS+2jomhgnzNc223cGvZS0HaSD0XLjbaSjElhIr+AAAAAXRSTlMAQObYZgAAAHlJREFUCNdNyosOwyAIhWHAQS1Vt7a77/3fcxxdmv0xwmckutAR1nkm4ggbyEcg/wWmlGLDAA3oL50xi6fk5ffZ3E2E3QfZDCcCN2YtbEWZt+Drc6u6rlqv7Uk0LdKqqr5rk2UCRXOk0vmQKGfc94nOJyQjouF9H/wCc9gECEYfONoAAAAASUVORK5CYII=",alt:"Scala Steward badge"})})]}),"\n",(0,s.jsx)(a.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(a.p,{children:"Apache Kafka is a distributed event streaming platform that acts as a distributed publish-subscribe messaging system. It enables us to build distributed streaming data pipelines and event-driven applications."}),"\n",(0,s.jsx)(a.p,{children:"Kafka has a mature Java client for producing and consuming events, but it has a low-level API. ZIO Kafka is a ZIO native client for Apache Kafka. It has a high-level streaming API on top of the Java client. So we can produce and consume events using the declarative concurrency model of ZIO Streams."}),"\n",(0,s.jsx)(a.h2,{id:"installation",children:"Installation"}),"\n",(0,s.jsxs)(a.p,{children:["In order to use this library, we need to add the following line in our ",(0,s.jsx)(a.code,{children:"build.sbt"})," file:"]}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-scala",children:'libraryDependencies += "dev.zio" %% "zio-kafka"         % "2.9.1"\nlibraryDependencies += "dev.zio" %% "zio-kafka-testkit" % "2.9.1" % Test\n'})}),"\n",(0,s.jsxs)(a.p,{children:["Snapshots are available on Sonatype's snapshot repository ",(0,s.jsx)(a.a,{href:"https://oss.sonatype.org/content/repositories/snapshots",children:"https://oss.sonatype.org/content/repositories/snapshots"}),".\n",(0,s.jsx)(a.a,{href:"https://oss.sonatype.org/content/repositories/snapshots/dev/zio/zio-kafka_3/",children:"Browse here"})," to find available versions."]}),"\n",(0,s.jsxs)(a.p,{children:["For ",(0,s.jsx)(a.code,{children:"zio-kafka-testkit"})," together with Scala 3, you also need to add the following to your ",(0,s.jsx)(a.code,{children:"build.sbt"})," file:"]}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-scala",children:'excludeDependencies += "org.scala-lang.modules" % "scala-collection-compat_2.13"\n'})}),"\n",(0,s.jsx)(a.h2,{id:"example",children:"Example"}),"\n",(0,s.jsxs)(a.p,{children:["Let's write a simple Kafka producer and consumer using ZIO Kafka with ZIO Streams. Before everything, we need a running instance of Kafka. We can do that by saving the following docker-compose script in the ",(0,s.jsx)(a.code,{children:"docker-compose.yml"})," file and run ",(0,s.jsx)(a.code,{children:"docker-compose up"}),":"]}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-yaml",children:"version: '2'\nservices:\n  zookeeper:\n    image: confluentinc/cp-zookeeper:latest\n    environment:\n      ZOOKEEPER_CLIENT_PORT: 2181\n      ZOOKEEPER_TICK_TIME: 2000\n    ports:\n      - 22181:2181\n  \n  kafka:\n    image: confluentinc/cp-kafka:latest\n    depends_on:\n      - zookeeper\n    ports:\n      - 29092:29092\n    environment:\n      KAFKA_BROKER_ID: 1\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT\n      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT\n      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n"})}),"\n",(0,s.jsx)(a.p,{children:"Now, we can run our ZIO Kafka Streaming application:"}),"\n",(0,s.jsx)(a.pre,{children:(0,s.jsx)(a.code,{className:"language-scala",children:'import zio._\nimport zio.kafka.consumer._\nimport zio.kafka.producer.{Producer, ProducerSettings}\nimport zio.kafka.serde._\nimport zio.stream.ZStream\n\nobject MainApp extends ZIOAppDefault {\n  val producer: ZStream[Producer, Throwable, Nothing] =\n    ZStream\n      .repeatZIO(Random.nextIntBetween(0, Int.MaxValue))\n      .schedule(Schedule.fixed(2.seconds))\n      .mapZIO { random =>\n        Producer.produce[Any, Long, String](\n          topic = "random",\n          key = random % 4,\n          value = random.toString,\n          keySerializer = Serde.long,\n          valueSerializer = Serde.string\n        )\n      }\n      .drain\n\n  val consumer: ZStream[Consumer, Throwable, Nothing] =\n    Consumer\n      .plainStream(Subscription.topics("random"), Serde.long, Serde.string)\n      .tap(r => Console.printLine(r.value))\n      .map(_.offset)\n      .aggregateAsync(Consumer.offsetBatches)\n      .mapZIO(_.commit)\n      .drain\n\n  def producerLayer =\n    ZLayer.scoped(\n      Producer.make(\n        settings = ProducerSettings(List("localhost:29092"))\n      )\n    )\n\n  def consumerLayer =\n    ZLayer.scoped(\n      Consumer.make(\n        ConsumerSettings(List("localhost:29092")).withGroupId("group")\n      )\n    )\n\n  override def run =\n    producer.merge(consumer)\n      .runDrain\n      .provide(producerLayer, consumerLayer)\n}\n'})}),"\n",(0,s.jsx)(a.h2,{id:"resources",children:"Resources"}),"\n",(0,s.jsx)(a.h3,{id:"articles",children:"Articles"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://zio.dev/guides/tutorials/producing-consuming-data-from-kafka-topics/",children:"ZIO Kafka tutorial"})," by the ZIO-kafka team"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://day-to-day-stuff.blogspot.com/2024/12/zio-kafka-faster-than-java-kafka.html",children:"ZIO Kafka faster than Java Kafka"})," by Erik van Oosten (December 2024)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.baeldung.com/scala/zio-kafka-intro",children:"Introduction to zio-kafka"})," by Stefanos Georgakis, Baeldung (January 2023)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://scalac.io/blog/streaming-microservices-with-zio-and-kafka/",children:"How to implement streaming microservices with ZIO 2 and Kafka"})," by Jorge Vasquez, Scalac (June 2023)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://medium.com/@knoldus/zio-kafka-d865fc20174a",children:"Zio Kafka"})," by Knoldus Inc (January 2022)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://pramodshehan.medium.com/writing-a-simple-producer-and-consumer-using-zio-workflows-a57def08210c",children:"Writing a Simple Producer and Consumer Using ZIO Workflows"})," by Pramod Shehan (December 2022)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.ziverge.com/post/zio-kafka-with-transactions---a-debugging-story/",children:"ZIO Kafka with transactions - a debugging story"})," by Daniel Vigovszky, Ziverge (June 2022)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://blog.knoldus.com/introduction-to-zio-kafka/",children:"Introduction to Zio-Kafka"})," by Akash Kumar (March 2022)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://blog.nashtechglobal.com/introduction-to-zio-kafka/",children:"Introduction to Zio-Kafka"})," by Khalid Ahmed, Nash Tech (March 2022)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://rockthejvm.com/articles/zio-kafka/",children:"ZIO Kafka: A Practical Streaming Tutorial"})," by Riccardo Cardin, Rock the JVM (August 2021)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://functional.works-hub.com/learn/using-zio-kafka-with-offset-storage-in-postgres-for-transactional-processing-be4a2",children:"Using ZIO Kafka with offset storage in Postgres for transactional processing"})," by Marek Kadek (March 2021)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://scalac.io/streaming-microservices-with-zio-and-kafka/",children:"Streaming microservices with ZIO and Kafka"})," by Aleksandar Skrbic (February 2021)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.ziverge.com/post/an-introduction-to-zio-kafka/",children:"An Introduction to ZIO Kafka"})," by Ziverge (April 2020)"]}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"video",children:"Video"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.youtube.com/watch?v=McnC2UU-RIE",children:"Optimizing Data Transfer Kafka to BQ: let's use Scala to make it custom"})," by Dario Amorosi, Adevinta (November 2024)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.youtube.com/watch?v=MJoRwEyyVxM",children:"Making ZIO-Kafka Safer and Faster in 2023"})," by Erik van Oosten (November 2023)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.youtube.com/watch?v=ExFjjczwwHs",children:"ZIO Kafka with Scala: A Tutorial"})," by Rock the JVM (August 2021)"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://www.youtube.com/watch?v=GECv1ONieLw",children:"ZIO WORLD - ZIO Kafka"})," by Aleksandar Skrbic (March 2020) \u2014 Aleksandar Skrbic presented ZIO Kafka, a critical library for the modern Scala developer, which hides some of the complexities of Kafka."]}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"example-projects",children:"Example projects"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://github.com/adevinta/kafka-bigquery-express/",children:"Kafka BigQuery Express"}),' by Adevinta (November 2024) A production system to copy data from Kafka to BigQuery, safely and cost-effectively. (See also the video "Optimizing Data Transfer...".)']}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://github.com/ScalaConsultants/zio-kafka-showcase",children:"zio-kafka-showcase"})," by Jorge V\xe1squez, Example project that demonstrates how to build Kafka based microservices with Scala and ZIO"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://github.com/pramodShehan5/zio-kafka-demo1",children:"zio-kafka-demo1"})," (December 2022), example consumer and producer using zio-kafka 2.0.5"]}),"\n",(0,s.jsxs)(a.li,{children:[(0,s.jsx)(a.a,{href:"https://github.com/zivergetech/zio-kafka-example-app",children:"zio-kafka-example-app"})," by Ziverge (December 2020), example application using zio-kafka 0.8.0"]}),"\n"]}),"\n",(0,s.jsx)(a.h2,{id:"adopters",children:"Adopters"}),"\n",(0,s.jsx)(a.p,{children:"Here is a partial list of companies using zio-kafka in production."}),"\n",(0,s.jsxs)(a.p,{children:["Want to see your company here? ",(0,s.jsx)(a.a,{href:"https://github.com/zio/zio-kafka/edit/master/docs/index.md",children:"Submit a PR"}),"!"]}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:(0,s.jsx)(a.a,{href:"https://www.conduktor.io",children:"Conduktor"})}),"\n",(0,s.jsx)(a.li,{children:(0,s.jsx)(a.a,{href:"https://www.kelkoogroup.com",children:"KelkooGroup"})}),"\n",(0,s.jsx)(a.li,{children:(0,s.jsx)(a.a,{href:"https://rocker.com",children:"Rocker"})}),"\n"]}),"\n",(0,s.jsx)(a.h2,{id:"performance",children:"Performance"}),"\n",(0,s.jsxs)(a.p,{children:["By default, zio-kafka programs process partitions in parallel. The default java-kafka client does not provide parallel\nprocessing. Of course, there is some overhead in buffering records and distributing them to the fibers that need them.\nOn 2024-11-23, we estimated that zio-kafka consumes faster than the java-kafka client when processing takes more than\n~1.2ms per 1000 records. The precise time depends on many factors. Please\nsee ",(0,s.jsx)(a.a,{href:"https://day-to-day-stuff.blogspot.com/2024/12/zio-kafka-faster-than-java-kafka.html",children:"this article"})," for more\ndetails."]}),"\n",(0,s.jsx)(a.p,{children:"If you do not care for the convenient ZStream based API that zio-kafka brings, and latency is of absolute importance,\nusing the java based Kafka client directly is still the better choice."})]})}function h(e={}){const{wrapper:a}={...(0,t.R)(),...e.components};return a?(0,s.jsx)(a,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,a,n)=>{n.d(a,{R:()=>o,x:()=>r});var i=n(96540);const s={},t=i.createContext(s);function o(e){const a=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function r(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(t.Provider,{value:a},e.children)}}}]);