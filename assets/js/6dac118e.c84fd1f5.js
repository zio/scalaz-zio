"use strict";(self.webpackChunkzio_site=self.webpackChunkzio_site||[]).push([[25394],{64384:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>p,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"reference/stream/zpipeline","title":"ZPipeline","description":"Introduction","source":"@site/docs/reference/stream/zpipeline.md","sourceDirName":"reference/stream","slug":"/reference/stream/zpipeline","permalink":"/reference/stream/zpipeline","draft":false,"unlisted":false,"editUrl":"https://github.com/zio/zio/edit/series/2.x/docs/reference/stream/zpipeline.md","tags":[],"version":"current","frontMatter":{"id":"zpipeline","title":"ZPipeline"},"sidebar":"reference-sidebar","previous":{"title":"Scheduling","permalink":"/reference/stream/zstream/scheduling"},"next":{"title":"Introduction to ZSink","permalink":"/reference/stream/zsink/"}}');var t=i(74848),r=i(28453);const l={id:"zpipeline",title:"ZPipeline"},a=void 0,o={},d=[{value:"Introduction",id:"introduction",level:2},{value:"Creation",id:"creation",level:2},{value:"From Function",id:"from-function",level:3},{value:"Built-in Pipelines",id:"built-in-pipelines",level:2},{value:"Identity",id:"identity",level:3},{value:"Splitting",id:"splitting",level:3},{value:"Dropping",id:"dropping",level:3},{value:"Prepending",id:"prepending",level:3},{value:"Compression",id:"compression",level:3},{value:"Decompression",id:"decompression",level:3},{value:"Decoders",id:"decoders",level:3},{value:"Operations",id:"operations",level:2},{value:"Output Transformation (Mapping)",id:"output-transformation-mapping",level:3},{value:"Input Transformation (Contramap)",id:"input-transformation-contramap",level:3},{value:"Composing",id:"composing",level:3}];function c(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsxs)(n.p,{children:["A ",(0,t.jsx)(n.code,{children:"ZPipeline[+LowerEnv, -UpperEnv, +LowerErr, -UpperErr, +LowerElem, -UpperElem]"})," is a stream transformer. Pipelines accept a stream as input, and return the transformed stream as output."]}),"\n",(0,t.jsx)(n.p,{children:"ZPipelines can be thought of as a recipe for calling a bunch of methods on a source stream, to yield a new (transformed) stream. A nice mental model is the following type alias:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"type ZPipeline[Env, Err, In, Out] = ZStream[Env, Err, In] => ZStream[Env, Err, Out]\n"})}),"\n",(0,t.jsx)(n.p,{children:"There is no fundamental requirement for pipelines to exist, because everything pipelines do can be done directly on a stream. However, because pipelines separate the stream transformation from the source stream itself, it becomes possible to abstract over stream transformations at the level of values, creating, storing, and passing around reusable transformation pipelines that can be applied to many different streams."}),"\n",(0,t.jsx)(n.h2,{id:"creation",children:"Creation"}),"\n",(0,t.jsx)(n.h3,{id:"from-function",children:"From Function"}),"\n",(0,t.jsxs)(n.p,{children:["By using ",(0,t.jsx)(n.code,{children:"ZPipeline.map"})," we convert a function into a pipeline. Let's create a pipeline which converts a stream of strings into a stream of characters:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"val chars = \n ZPipeline.map[String, Chunk[Char]](s => Chunk.fromArray(s.toArray)) >>>\n   ZPipeline.mapChunks[Chunk[Char], Char](_.flatten)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["There is also a ",(0,t.jsx)(n.code,{children:"ZPipeline.mapZIO"})," which is an effectful version of this constructor."]}),"\n",(0,t.jsx)(n.h2,{id:"built-in-pipelines",children:"Built-in Pipelines"}),"\n",(0,t.jsx)(n.h3,{id:"identity",children:"Identity"}),"\n",(0,t.jsx)(n.p,{children:"The identity pipeline passes elements through without any modification:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"ZStream(1,2,3).via(ZPipeline.identity[Int])\n// Ouput: 1, 2, 3\n"})}),"\n",(0,t.jsx)(n.h3,{id:"splitting",children:"Splitting"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ZPipeline.splitOn"})," \u2014 A pipeline that splits strings on a delimiter:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:'ZStream("1-2-3", "4-5", "6", "7-8-9-10")\n  .via(ZPipeline.splitOn("-"))\n  .map(_.toInt)\n// Ouput: 1, 2, 3, 4, 5, 6, 7, 8, 9 10\n'})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ZPipeline.splitLines"})," \u2014 A pipeline that splits strings on newlines. Handles both Windows newlines (",(0,t.jsx)(n.code,{children:"\\r\\n"}),") and UNIX newlines (",(0,t.jsx)(n.code,{children:"\\n"}),"):"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:'ZStream("This is the first line.\\nSecond line.\\nAnd the last line.")\n  .via(ZPipeline.splitLines)\n// Output: "This is the first line.", "Second line.", "And the last line."\n'})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ZPipeline.splitOnChunk"})," \u2014 A pipeline that splits elements on a delimiter and transforms the splits into desired output:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"ZStream(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n  .via(ZPipeline.splitOnChunk(Chunk(4, 5, 6)))\n// Output: Chunk(1, 2, 3), Chunk(7, 8, 9, 10)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"dropping",children:"Dropping"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ZPipeline.dropWhile"})," \u2014 Creates a pipeline that starts consuming values as soon as one fails the given predicate:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"ZStream(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n  .via(ZPipeline.dropWhile((x: Int) => x <= 5))\n// Output: 6, 7, 8, 9, 10\n"})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"ZPipeline"})," also has ",(0,t.jsx)(n.code,{children:"dropWhileZIO"})," which takes an effectful predicate ",(0,t.jsx)(n.code,{children:"p: I => ZIO[R, E, Boolean]"}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"prepending",children:"Prepending"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"ZPipeline.prepend"})," creates a pipeline that emits the provided chunks before emitting any other values:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"ZStream(2, 3, 4).via(\n  ZPipeline.prepend(Chunk(0, 1))\n)\n// Output: 0, 1, 2, 3, 4\n"})}),"\n",(0,t.jsx)(n.h3,{id:"compression",children:"Compression"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ZPipeline.deflate"})," \u2014 The ",(0,t.jsx)(n.code,{children:"deflate"})," pipeline compresses a stream of bytes as specified by ",(0,t.jsx)(n.a,{href:"https://tools.ietf.org/html/rfc1951",children:"RFC 1951"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"import zio.stream.ZStream\nimport zio.stream.ZPipeline.deflate\nimport zio.stream.compression.{CompressionLevel, CompressionStrategy, FlushMode}\n\ndef compressWithDeflate(clearText: ZStream[Any, Nothing, Byte]): ZStream[Any, Nothing, Byte] = {\n  val bufferSize: Int = 64 * 1024 // Internal buffer size. Few times bigger than upstream chunks should work well.\n  val noWrap: Boolean = false // For HTTP Content-Encoding should be false.\n  val level: CompressionLevel = CompressionLevel.DefaultCompression\n  val strategy: CompressionStrategy = CompressionStrategy.DefaultStrategy\n  val flushMode: FlushMode = FlushMode.NoFlush\n  clearText.via(deflate(bufferSize, noWrap, level, strategy, flushMode))\n}\n\ndef deflateWithDefaultParameters(clearText: ZStream[Any, Nothing, Byte]): ZStream[Any, Nothing, Byte] =\n  clearText.via(deflate())\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ZPipeline.gzip"})," \u2014 The ",(0,t.jsx)(n.code,{children:"gzip"})," pipeline compresses a stream of bytes as using ",(0,t.jsx)(n.em,{children:"gzip"})," method:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:'import zio.stream.compression._\n\nZStream\n  .fromFileName("file.txt")\n  .via(\n    ZPipeline.gzip(\n      bufferSize = 64 * 1024,\n      level = CompressionLevel.DefaultCompression,\n      strategy = CompressionStrategy.DefaultStrategy,\n      flushMode = FlushMode.NoFlush\n    )\n  )\n  .run(\n    ZSink.fromFileName("file.gz")\n  )\n'})}),"\n",(0,t.jsx)(n.h3,{id:"decompression",children:"Decompression"}),"\n",(0,t.jsxs)(n.p,{children:["If we are reading ",(0,t.jsx)(n.code,{children:"Content-Encoding: deflate"}),", ",(0,t.jsx)(n.code,{children:"Content-Encoding: gzip"})," streams, or other such streams of compressed data, the following pipelines can be helpful. Both decompression methods will fail with ",(0,t.jsx)(n.code,{children:"CompressionException"})," when input wasn't properly compressed:"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ZPipeline.inflate"})," \u2014 This pipeline allows decompressing stream of ",(0,t.jsx)(n.em,{children:"deflated"})," inputs, according to ",(0,t.jsx)(n.a,{href:"https://tools.ietf.org/html/rfc1951",children:"RFC 1951"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"import zio.stream.ZStream\nimport zio.stream.ZPipeline.{ gunzip, inflate }\nimport zio.stream.compression.CompressionException\n\ndef decompressDeflated(deflated: ZStream[Any, Nothing, Byte]): ZStream[Any, CompressionException, Byte] = {\n  val bufferSize: Int = 64 * 1024 // Internal buffer size. Few times bigger than upstream chunks should work well.\n  val noWrap: Boolean = false     // For HTTP Content-Encoding should be false.\n  deflated.via(inflate(bufferSize, noWrap))\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ZPipeline.gunzip"})," \u2014 This pipeline can be used to decompress stream of ",(0,t.jsx)(n.em,{children:"gzipped"})," inputs, according to ",(0,t.jsx)(n.a,{href:"https://tools.ietf.org/html/rfc1952",children:"RFC 1952"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"import zio.stream.ZStream\nimport zio.stream.ZPipeline.{ gunzip, inflate }\nimport zio.stream.compression.CompressionException\n\ndef decompressGzipped(gzipped: ZStream[Any, Nothing, Byte]): ZStream[Any, CompressionException, Byte] = {\n  val bufferSize: Int = 64 * 1024 // Internal buffer size. Few times bigger than upstream chunks should work well.\n  gzipped.via(gunzip(bufferSize))\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"ZPipeline.gunzipAuto"})," \u2014 This pipeline can be used to decompress stream of ",(0,t.jsx)(n.em,{children:"possibly"})," ",(0,t.jsx)(n.em,{children:"gzipped"})," inputs, according to ",(0,t.jsx)(n.a,{href:"https://tools.ietf.org/html/rfc1952",children:"RFC 1952"}),". If the input is gzipped, it will be decompressed; if not, it will be passed downstream as-is:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"import zio.stream.ZStream\nimport zio.stream.ZPipeline.gunzipAuto\nimport zio.stream.compression.CompressionException\n\ndef decompressMaybeGzipped(maybeGzipped: ZStream[Any, Nothing, Byte]): ZStream[Any, CompressionException, Byte] = {\n  val bufferSize: Int = 64 * 1024 // Internal buffer size. Few times bigger than upstream chunks should work well.\n  maybeGzipped.via(gunzipAuto(bufferSize))\n}\n"})}),"\n",(0,t.jsx)(n.h3,{id:"decoders",children:"Decoders"}),"\n",(0,t.jsx)(n.p,{children:"ZIO stream has a wide variety of pipelines to decode chunks of bytes into strings:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Decoder"}),(0,t.jsx)(n.th,{children:"Input"}),(0,t.jsx)(n.th,{children:"Output"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"ZPipeline.utfDecode"})}),(0,t.jsx)(n.td,{children:"Unicode bytes"}),(0,t.jsx)(n.td,{children:"String"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"ZPipeline.utf8Decode"})}),(0,t.jsx)(n.td,{children:"UTF-8 bytes"}),(0,t.jsx)(n.td,{children:"String"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"ZPipeline.utf16Decode"})}),(0,t.jsx)(n.td,{children:"UTF-16"}),(0,t.jsx)(n.td,{children:"String"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"ZPipeline.utf16BEDecode"})}),(0,t.jsx)(n.td,{children:"UTF-16BE bytes"}),(0,t.jsx)(n.td,{children:"String"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"ZPipeline.utf16LEDecode"})}),(0,t.jsx)(n.td,{children:"UTF-16LE bytes"}),(0,t.jsx)(n.td,{children:"String"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"ZPipeline.utf32Decode"})}),(0,t.jsx)(n.td,{children:"UTF-32 bytes"}),(0,t.jsx)(n.td,{children:"String"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"ZPipeline.utf32BEDecode"})}),(0,t.jsx)(n.td,{children:"UTF-32BE bytes"}),(0,t.jsx)(n.td,{children:"String"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"ZPipeline.utf32LEDecode"})}),(0,t.jsx)(n.td,{children:"UTF-32LE bytes"}),(0,t.jsx)(n.td,{children:"String"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"ZPipeline.usASCIIDecode"})}),(0,t.jsx)(n.td,{children:"US-ASCII bytes"}),(0,t.jsx)(n.td,{children:"String"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"operations",children:"Operations"}),"\n",(0,t.jsx)(n.h3,{id:"output-transformation-mapping",children:"Output Transformation (Mapping)"}),"\n",(0,t.jsxs)(n.p,{children:["To transform the ",(0,t.jsx)(n.em,{children:"outputs"})," of the pipeline, we can use the ",(0,t.jsx)(n.code,{children:"ZPipeline#map"})," combinator for the success channel, and the ",(0,t.jsx)(n.code,{children:"ZPipeline#mapError"})," combinator for the failure channel. Also, the ",(0,t.jsx)(n.code,{children:"ZPipeline.mapChunks"})," takes a function of type ",(0,t.jsx)(n.code,{children:"Chunk[O] => Chunk[O2]"})," and transforms chunks emitted by the pipeline."]}),"\n",(0,t.jsx)(n.h3,{id:"input-transformation-contramap",children:"Input Transformation (Contramap)"}),"\n",(0,t.jsxs)(n.p,{children:["To transform the ",(0,t.jsx)(n.em,{children:"inputs"})," of the pipeline, we can use the ",(0,t.jsx)(n.code,{children:"ZPipeline#contramap"})," combinator. It takes a map function of type ",(0,t.jsx)(n.code,{children:"J => I"})," and convert a ",(0,t.jsx)(n.code,{children:"ZPipeline[R, E, I, O]"})," to ",(0,t.jsx)(n.code,{children:"ZPipeline[R, E, J, O]"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:"class ZPipeline[-R, +E, -I, +O] {\n  final def contramap[J](f: J => I): ZPipeline[R, E, J, O] = ???\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Let's create an integer parser pipeline using ",(0,t.jsx)(n.code,{children:"ZPipeline.contramap"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:'val numbers: ZStream[Any, Nothing, Int] =\n ZStream("1-2-3-4-5")\n   .mapConcat(_.split("-"))\n   .via(\n     ZPipeline.map[String, Int](_.toInt)\n   )\n'})}),"\n",(0,t.jsx)(n.h3,{id:"composing",children:"Composing"}),"\n",(0,t.jsx)(n.p,{children:"We can compose pipelines in two ways:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Composing Two Pipelines"})," \u2014 One pipeline can be composed with another pipeline, resulting in a composite pipeline:"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:'val lines: ZStream[Any, Throwable, String] =\n  ZStream\n    .fromFileName("file.txt")\n    .via(\n      ZPipeline.utf8Decode >>> ZPipeline.splitLines\n    )\n'})}),"\n",(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Composing ZPipeline with ZSink"})," \u2014 One pipeline can be composed with a sink, resulting in a sink that processes elements by piping them through the pipeline and piping the results into the sink:"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-scala",children:'import java.nio.charset.CharacterCodingException\n\nval refine: ZIO[Any, Throwable, Long] = {\n  val stream: ZStream[Any, Throwable, Byte] = ZStream.fromFileName("file.txt")\n  val pipeline: ZPipeline[Any, CharacterCodingException, Byte, String] =\n    ZPipeline.utf8Decode >>> ZPipeline.splitLines >>> ZPipeline.filter[String](_.contains(\'\u20bf\'))\n  val fileSink: ZSink[Any, Throwable, String, Byte, Long] = ZSink\n    .fromFileName("file.refined.txt")\n    .contramapChunks[String](\n      _.flatMap(line => (line + System.lineSeparator()).getBytes())\n    )\n  val pipeSink: ZSink[Any, Throwable, Byte, Byte, Long] = pipeline >>> fileSink\n  stream >>> pipeSink\n}\n'})})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>a});var s=i(96540);const t={},r=s.createContext(t);function l(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);